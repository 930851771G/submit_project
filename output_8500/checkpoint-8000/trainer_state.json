{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0303967027305512,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.7396549582481384,
      "learning_rate": 4.994117647058824e-05,
      "loss": 2.0843,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7169257998466492,
      "learning_rate": 4.9882352941176476e-05,
      "loss": 2.0063,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.5498374700546265,
      "learning_rate": 4.9823529411764706e-05,
      "loss": 1.4857,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9123143553733826,
      "learning_rate": 4.976470588235294e-05,
      "loss": 1.9479,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6916724443435669,
      "learning_rate": 4.970588235294118e-05,
      "loss": 2.0631,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.715797483921051,
      "learning_rate": 4.9647058823529416e-05,
      "loss": 2.3826,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5133962631225586,
      "learning_rate": 4.958823529411765e-05,
      "loss": 1.6836,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7555455565452576,
      "learning_rate": 4.952941176470588e-05,
      "loss": 1.8862,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7520318031311035,
      "learning_rate": 4.947058823529412e-05,
      "loss": 2.5824,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6737620234489441,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 2.1768,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6378394961357117,
      "learning_rate": 4.935294117647059e-05,
      "loss": 1.4663,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6694679260253906,
      "learning_rate": 4.929411764705882e-05,
      "loss": 1.9835,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8011227250099182,
      "learning_rate": 4.9235294117647065e-05,
      "loss": 2.1732,
      "step": 130
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5817644596099854,
      "learning_rate": 4.9176470588235295e-05,
      "loss": 1.4515,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.65079265832901,
      "learning_rate": 4.911764705882353e-05,
      "loss": 2.0902,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.681136429309845,
      "learning_rate": 4.905882352941177e-05,
      "loss": 1.7423,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.865554928779602,
      "learning_rate": 4.9e-05,
      "loss": 1.747,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6741632223129272,
      "learning_rate": 4.894117647058824e-05,
      "loss": 2.4369,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8510251045227051,
      "learning_rate": 4.888235294117647e-05,
      "loss": 2.0585,
      "step": 190
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9345579147338867,
      "learning_rate": 4.882352941176471e-05,
      "loss": 1.7128,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6858922243118286,
      "learning_rate": 4.8764705882352945e-05,
      "loss": 2.356,
      "step": 210
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1562786102294922,
      "learning_rate": 4.870588235294118e-05,
      "loss": 1.8626,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8216276168823242,
      "learning_rate": 4.864705882352941e-05,
      "loss": 1.6861,
      "step": 230
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6591823101043701,
      "learning_rate": 4.858823529411765e-05,
      "loss": 1.8522,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8712974190711975,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 2.4756,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.945023238658905,
      "learning_rate": 4.8470588235294115e-05,
      "loss": 1.8086,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8521285057067871,
      "learning_rate": 4.841176470588236e-05,
      "loss": 2.0532,
      "step": 270
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8471000790596008,
      "learning_rate": 4.835294117647059e-05,
      "loss": 1.8673,
      "step": 280
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7142120003700256,
      "learning_rate": 4.829411764705883e-05,
      "loss": 1.6822,
      "step": 290
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2705433368682861,
      "learning_rate": 4.823529411764706e-05,
      "loss": 2.0034,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.242003083229065,
      "learning_rate": 4.81764705882353e-05,
      "loss": 2.0078,
      "step": 310
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7385304570198059,
      "learning_rate": 4.8117647058823535e-05,
      "loss": 1.8828,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9220168590545654,
      "learning_rate": 4.8058823529411765e-05,
      "loss": 2.1458,
      "step": 330
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6831074953079224,
      "learning_rate": 4.8e-05,
      "loss": 1.9469,
      "step": 340
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7665641903877258,
      "learning_rate": 4.794117647058824e-05,
      "loss": 1.6115,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.009366512298584,
      "learning_rate": 4.7882352941176475e-05,
      "loss": 1.6954,
      "step": 360
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.127745509147644,
      "learning_rate": 4.7823529411764704e-05,
      "loss": 2.0792,
      "step": 370
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.008154034614563,
      "learning_rate": 4.776470588235295e-05,
      "loss": 2.5528,
      "step": 380
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.935829758644104,
      "learning_rate": 4.770588235294118e-05,
      "loss": 2.1982,
      "step": 390
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0530284643173218,
      "learning_rate": 4.7647058823529414e-05,
      "loss": 2.0747,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1127703189849854,
      "learning_rate": 4.758823529411765e-05,
      "loss": 2.0066,
      "step": 410
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.904037594795227,
      "learning_rate": 4.752941176470588e-05,
      "loss": 1.5822,
      "step": 420
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3187386989593506,
      "learning_rate": 4.7470588235294124e-05,
      "loss": 2.0417,
      "step": 430
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8978285193443298,
      "learning_rate": 4.7411764705882354e-05,
      "loss": 2.0516,
      "step": 440
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0291705131530762,
      "learning_rate": 4.735294117647059e-05,
      "loss": 2.0509,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8796937465667725,
      "learning_rate": 4.729411764705883e-05,
      "loss": 1.5584,
      "step": 460
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7101024985313416,
      "learning_rate": 4.7235294117647064e-05,
      "loss": 1.7059,
      "step": 470
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1913437843322754,
      "learning_rate": 4.7176470588235294e-05,
      "loss": 1.6747,
      "step": 480
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2967019081115723,
      "learning_rate": 4.711764705882353e-05,
      "loss": 2.0231,
      "step": 490
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1487231254577637,
      "learning_rate": 4.705882352941177e-05,
      "loss": 2.3678,
      "step": 500
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.007578686752745535,
      "eval_rouge-1": 14.861324,
      "eval_rouge-2": 2.4789380000000003,
      "eval_rouge-l": 8.489636,
      "eval_runtime": 791.0178,
      "eval_samples_per_second": 0.063,
      "eval_steps_per_second": 0.005,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1327245235443115,
      "learning_rate": 4.7e-05,
      "loss": 1.4586,
      "step": 510
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0759632587432861,
      "learning_rate": 4.694117647058824e-05,
      "loss": 1.503,
      "step": 520
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2739144563674927,
      "learning_rate": 4.688235294117647e-05,
      "loss": 1.9756,
      "step": 530
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1042938232421875,
      "learning_rate": 4.682352941176471e-05,
      "loss": 1.6475,
      "step": 540
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0690494775772095,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 1.8079,
      "step": 550
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.188957929611206,
      "learning_rate": 4.6705882352941174e-05,
      "loss": 1.839,
      "step": 560
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3997347354888916,
      "learning_rate": 4.664705882352942e-05,
      "loss": 2.1216,
      "step": 570
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2239084243774414,
      "learning_rate": 4.658823529411765e-05,
      "loss": 2.3236,
      "step": 580
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.452799916267395,
      "learning_rate": 4.6529411764705884e-05,
      "loss": 1.3247,
      "step": 590
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1526904106140137,
      "learning_rate": 4.647058823529412e-05,
      "loss": 2.1531,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1472471952438354,
      "learning_rate": 4.641176470588236e-05,
      "loss": 1.8444,
      "step": 610
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2528969049453735,
      "learning_rate": 4.635294117647059e-05,
      "loss": 1.7568,
      "step": 620
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3372067213058472,
      "learning_rate": 4.6294117647058824e-05,
      "loss": 1.6377,
      "step": 630
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.25386381149292,
      "learning_rate": 4.623529411764706e-05,
      "loss": 2.2869,
      "step": 640
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1897941827774048,
      "learning_rate": 4.61764705882353e-05,
      "loss": 2.1509,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.4586433172225952,
      "learning_rate": 4.6117647058823534e-05,
      "loss": 1.6164,
      "step": 660
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8846438527107239,
      "learning_rate": 4.605882352941176e-05,
      "loss": 1.9242,
      "step": 670
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2287791967391968,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.3812,
      "step": 680
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3532061576843262,
      "learning_rate": 4.594117647058824e-05,
      "loss": 1.3757,
      "step": 690
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5462522506713867,
      "learning_rate": 4.588235294117647e-05,
      "loss": 1.9536,
      "step": 700
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5861589908599854,
      "learning_rate": 4.582352941176471e-05,
      "loss": 1.9828,
      "step": 710
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9763641357421875,
      "learning_rate": 4.576470588235294e-05,
      "loss": 1.6749,
      "step": 720
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.961509644985199,
      "learning_rate": 4.5705882352941177e-05,
      "loss": 2.0053,
      "step": 730
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.174042820930481,
      "learning_rate": 4.564705882352941e-05,
      "loss": 2.2366,
      "step": 740
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6947141885757446,
      "learning_rate": 4.558823529411765e-05,
      "loss": 1.5909,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6772977113723755,
      "learning_rate": 4.5529411764705886e-05,
      "loss": 2.1871,
      "step": 760
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5023149251937866,
      "learning_rate": 4.547058823529412e-05,
      "loss": 1.8749,
      "step": 770
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.860402226448059,
      "learning_rate": 4.541176470588235e-05,
      "loss": 1.5551,
      "step": 780
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5062893629074097,
      "learning_rate": 4.535294117647059e-05,
      "loss": 1.7247,
      "step": 790
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.553699254989624,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 2.1275,
      "step": 800
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2932320833206177,
      "learning_rate": 4.5235294117647056e-05,
      "loss": 1.9158,
      "step": 810
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3733667135238647,
      "learning_rate": 4.51764705882353e-05,
      "loss": 1.8575,
      "step": 820
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.5138239860534668,
      "learning_rate": 4.511764705882353e-05,
      "loss": 1.6347,
      "step": 830
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.796334147453308,
      "learning_rate": 4.5058823529411766e-05,
      "loss": 1.8974,
      "step": 840
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7259682416915894,
      "learning_rate": 4.5e-05,
      "loss": 1.9797,
      "step": 850
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2472668886184692,
      "learning_rate": 4.494117647058824e-05,
      "loss": 1.7184,
      "step": 860
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3183062076568604,
      "learning_rate": 4.4882352941176476e-05,
      "loss": 1.2646,
      "step": 870
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7057313919067383,
      "learning_rate": 4.4823529411764706e-05,
      "loss": 1.3718,
      "step": 880
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6512082815170288,
      "learning_rate": 4.476470588235294e-05,
      "loss": 2.0283,
      "step": 890
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8229845762252808,
      "learning_rate": 4.470588235294118e-05,
      "loss": 1.8168,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5238608121871948,
      "learning_rate": 4.4647058823529416e-05,
      "loss": 2.6278,
      "step": 910
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6909865140914917,
      "learning_rate": 4.4588235294117646e-05,
      "loss": 1.8347,
      "step": 920
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7688746452331543,
      "learning_rate": 4.452941176470589e-05,
      "loss": 1.669,
      "step": 930
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.340709924697876,
      "learning_rate": 4.447058823529412e-05,
      "loss": 1.86,
      "step": 940
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4118435382843018,
      "learning_rate": 4.4411764705882356e-05,
      "loss": 1.2219,
      "step": 950
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8621255159378052,
      "learning_rate": 4.435294117647059e-05,
      "loss": 2.0358,
      "step": 960
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.691055178642273,
      "learning_rate": 4.429411764705882e-05,
      "loss": 1.4031,
      "step": 970
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7289830446243286,
      "learning_rate": 4.4235294117647066e-05,
      "loss": 1.4543,
      "step": 980
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.684492588043213,
      "learning_rate": 4.4176470588235296e-05,
      "loss": 1.7481,
      "step": 990
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3468832969665527,
      "learning_rate": 4.411764705882353e-05,
      "loss": 2.1087,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "eval_bleu-4": 0.009577832318973968,
      "eval_rouge-1": 15.305781999999999,
      "eval_rouge-2": 2.5396780000000003,
      "eval_rouge-l": 10.07657,
      "eval_runtime": 767.3855,
      "eval_samples_per_second": 0.065,
      "eval_steps_per_second": 0.005,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.4899284839630127,
      "learning_rate": 4.405882352941177e-05,
      "loss": 1.665,
      "step": 1010
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5730372667312622,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.074,
      "step": 1020
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3447985649108887,
      "learning_rate": 4.3941176470588236e-05,
      "loss": 1.9928,
      "step": 1030
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0680789947509766,
      "learning_rate": 4.388235294117647e-05,
      "loss": 1.8004,
      "step": 1040
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.854514241218567,
      "learning_rate": 4.382352941176471e-05,
      "loss": 1.2935,
      "step": 1050
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.194340705871582,
      "learning_rate": 4.376470588235294e-05,
      "loss": 1.3931,
      "step": 1060
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.5379902124404907,
      "learning_rate": 4.370588235294118e-05,
      "loss": 1.6494,
      "step": 1070
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.519855260848999,
      "learning_rate": 4.364705882352941e-05,
      "loss": 2.1072,
      "step": 1080
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2680854797363281,
      "learning_rate": 4.358823529411765e-05,
      "loss": 1.7901,
      "step": 1090
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3285330533981323,
      "learning_rate": 4.3529411764705885e-05,
      "loss": 1.918,
      "step": 1100
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0877158641815186,
      "learning_rate": 4.3470588235294115e-05,
      "loss": 2.2697,
      "step": 1110
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4456621408462524,
      "learning_rate": 4.341176470588236e-05,
      "loss": 1.7907,
      "step": 1120
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.037639617919922,
      "learning_rate": 4.335294117647059e-05,
      "loss": 1.7176,
      "step": 1130
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8759605884552002,
      "learning_rate": 4.3294117647058825e-05,
      "loss": 2.215,
      "step": 1140
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1268205642700195,
      "learning_rate": 4.323529411764706e-05,
      "loss": 1.5476,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7071746587753296,
      "learning_rate": 4.31764705882353e-05,
      "loss": 1.5471,
      "step": 1160
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.3370885848999023,
      "learning_rate": 4.311764705882353e-05,
      "loss": 1.5448,
      "step": 1170
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2933474779129028,
      "learning_rate": 4.3058823529411765e-05,
      "loss": 1.7699,
      "step": 1180
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9315828084945679,
      "learning_rate": 4.3e-05,
      "loss": 1.9255,
      "step": 1190
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8792698383331299,
      "learning_rate": 4.294117647058823e-05,
      "loss": 1.7756,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7812600135803223,
      "learning_rate": 4.2882352941176475e-05,
      "loss": 1.9272,
      "step": 1210
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5101515054702759,
      "learning_rate": 4.2823529411764705e-05,
      "loss": 1.792,
      "step": 1220
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5062429904937744,
      "learning_rate": 4.276470588235295e-05,
      "loss": 1.962,
      "step": 1230
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.002393960952759,
      "learning_rate": 4.270588235294118e-05,
      "loss": 1.7518,
      "step": 1240
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4836792945861816,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 1.752,
      "step": 1250
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2557687759399414,
      "learning_rate": 4.258823529411765e-05,
      "loss": 1.6095,
      "step": 1260
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9959425926208496,
      "learning_rate": 4.252941176470588e-05,
      "loss": 1.9296,
      "step": 1270
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9475791454315186,
      "learning_rate": 4.247058823529412e-05,
      "loss": 2.0554,
      "step": 1280
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0245769023895264,
      "learning_rate": 4.2411764705882355e-05,
      "loss": 2.3018,
      "step": 1290
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6179943084716797,
      "learning_rate": 4.235294117647059e-05,
      "loss": 1.3739,
      "step": 1300
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7077521085739136,
      "learning_rate": 4.229411764705882e-05,
      "loss": 1.4225,
      "step": 1310
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9001059532165527,
      "learning_rate": 4.2235294117647065e-05,
      "loss": 1.7756,
      "step": 1320
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.234105348587036,
      "learning_rate": 4.2176470588235294e-05,
      "loss": 2.0502,
      "step": 1330
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.6927742958068848,
      "learning_rate": 4.211764705882353e-05,
      "loss": 2.1774,
      "step": 1340
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7491880655288696,
      "learning_rate": 4.205882352941177e-05,
      "loss": 1.9381,
      "step": 1350
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.949735403060913,
      "learning_rate": 4.2e-05,
      "loss": 2.0165,
      "step": 1360
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9890642166137695,
      "learning_rate": 4.194117647058824e-05,
      "loss": 1.607,
      "step": 1370
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5039284229278564,
      "learning_rate": 4.188235294117647e-05,
      "loss": 2.0575,
      "step": 1380
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7638623714447021,
      "learning_rate": 4.182352941176471e-05,
      "loss": 1.6077,
      "step": 1390
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7925562858581543,
      "learning_rate": 4.1764705882352944e-05,
      "loss": 2.2187,
      "step": 1400
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.825470209121704,
      "learning_rate": 4.170588235294118e-05,
      "loss": 2.0608,
      "step": 1410
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.746583342552185,
      "learning_rate": 4.164705882352941e-05,
      "loss": 1.668,
      "step": 1420
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.063490629196167,
      "learning_rate": 4.158823529411765e-05,
      "loss": 1.9237,
      "step": 1430
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.013375997543335,
      "learning_rate": 4.1529411764705884e-05,
      "loss": 2.0703,
      "step": 1440
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0612082481384277,
      "learning_rate": 4.147058823529412e-05,
      "loss": 1.7305,
      "step": 1450
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9417744874954224,
      "learning_rate": 4.141176470588236e-05,
      "loss": 1.3927,
      "step": 1460
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0757973194122314,
      "learning_rate": 4.135294117647059e-05,
      "loss": 2.2106,
      "step": 1470
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8396998643875122,
      "learning_rate": 4.129411764705883e-05,
      "loss": 1.5323,
      "step": 1480
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0148532390594482,
      "learning_rate": 4.123529411764706e-05,
      "loss": 2.2317,
      "step": 1490
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7623422145843506,
      "learning_rate": 4.11764705882353e-05,
      "loss": 1.7156,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "eval_bleu-4": 0.008565046644483211,
      "eval_rouge-1": 15.911608,
      "eval_rouge-2": 2.16901,
      "eval_rouge-l": 9.547432,
      "eval_runtime": 771.8785,
      "eval_samples_per_second": 0.065,
      "eval_steps_per_second": 0.005,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4623600244522095,
      "learning_rate": 4.1117647058823534e-05,
      "loss": 1.4984,
      "step": 1510
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.6378333568573,
      "learning_rate": 4.1058823529411764e-05,
      "loss": 2.2059,
      "step": 1520
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4674177169799805,
      "learning_rate": 4.1e-05,
      "loss": 2.2057,
      "step": 1530
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.5032272338867188,
      "learning_rate": 4.094117647058824e-05,
      "loss": 1.6221,
      "step": 1540
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6714071035385132,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 1.8375,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4111716747283936,
      "learning_rate": 4.082352941176471e-05,
      "loss": 1.8757,
      "step": 1560
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.114696741104126,
      "learning_rate": 4.076470588235295e-05,
      "loss": 1.6072,
      "step": 1570
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.435027003288269,
      "learning_rate": 4.070588235294118e-05,
      "loss": 1.6893,
      "step": 1580
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1450493335723877,
      "learning_rate": 4.0647058823529414e-05,
      "loss": 2.259,
      "step": 1590
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.252087354660034,
      "learning_rate": 4.058823529411765e-05,
      "loss": 1.3803,
      "step": 1600
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0177221298217773,
      "learning_rate": 4.052941176470588e-05,
      "loss": 1.9951,
      "step": 1610
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0915579795837402,
      "learning_rate": 4.0470588235294124e-05,
      "loss": 1.2339,
      "step": 1620
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0992345809936523,
      "learning_rate": 4.0411764705882353e-05,
      "loss": 2.0861,
      "step": 1630
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6855508089065552,
      "learning_rate": 4.035294117647059e-05,
      "loss": 2.356,
      "step": 1640
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.831886649131775,
      "learning_rate": 4.029411764705883e-05,
      "loss": 1.7846,
      "step": 1650
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.987322211265564,
      "learning_rate": 4.023529411764706e-05,
      "loss": 1.4786,
      "step": 1660
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8036322593688965,
      "learning_rate": 4.01764705882353e-05,
      "loss": 1.9509,
      "step": 1670
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.100874900817871,
      "learning_rate": 4.011764705882353e-05,
      "loss": 1.7814,
      "step": 1680
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.975669503211975,
      "learning_rate": 4.005882352941177e-05,
      "loss": 1.6768,
      "step": 1690
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5067853927612305,
      "learning_rate": 4e-05,
      "loss": 1.4431,
      "step": 1700
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.893838882446289,
      "learning_rate": 3.994117647058824e-05,
      "loss": 1.7137,
      "step": 1710
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8860816955566406,
      "learning_rate": 3.988235294117647e-05,
      "loss": 1.8672,
      "step": 1720
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.496612548828125,
      "learning_rate": 3.9823529411764706e-05,
      "loss": 2.4665,
      "step": 1730
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1365878582000732,
      "learning_rate": 3.976470588235294e-05,
      "loss": 2.0322,
      "step": 1740
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0327188968658447,
      "learning_rate": 3.970588235294117e-05,
      "loss": 1.7082,
      "step": 1750
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.6613212823867798,
      "learning_rate": 3.9647058823529416e-05,
      "loss": 1.4887,
      "step": 1760
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4245240688323975,
      "learning_rate": 3.9588235294117646e-05,
      "loss": 1.634,
      "step": 1770
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9364699125289917,
      "learning_rate": 3.952941176470588e-05,
      "loss": 1.8005,
      "step": 1780
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9637260437011719,
      "learning_rate": 3.947058823529412e-05,
      "loss": 1.4218,
      "step": 1790
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3562440872192383,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 1.8847,
      "step": 1800
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.663616895675659,
      "learning_rate": 3.935294117647059e-05,
      "loss": 2.013,
      "step": 1810
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9651999473571777,
      "learning_rate": 3.929411764705882e-05,
      "loss": 2.0958,
      "step": 1820
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.249924421310425,
      "learning_rate": 3.923529411764706e-05,
      "loss": 1.9987,
      "step": 1830
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5808236598968506,
      "learning_rate": 3.9176470588235296e-05,
      "loss": 1.4401,
      "step": 1840
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9374414682388306,
      "learning_rate": 3.911764705882353e-05,
      "loss": 1.5344,
      "step": 1850
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1319642066955566,
      "learning_rate": 3.905882352941176e-05,
      "loss": 1.3285,
      "step": 1860
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3826074600219727,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.4896,
      "step": 1870
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.489104986190796,
      "learning_rate": 3.8941176470588236e-05,
      "loss": 1.7168,
      "step": 1880
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.311724901199341,
      "learning_rate": 3.888235294117647e-05,
      "loss": 2.1339,
      "step": 1890
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.7383129596710205,
      "learning_rate": 3.882352941176471e-05,
      "loss": 1.7705,
      "step": 1900
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7104880809783936,
      "learning_rate": 3.876470588235294e-05,
      "loss": 1.4347,
      "step": 1910
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0491201877593994,
      "learning_rate": 3.870588235294118e-05,
      "loss": 1.4378,
      "step": 1920
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.099395751953125,
      "learning_rate": 3.864705882352941e-05,
      "loss": 1.8832,
      "step": 1930
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.905476450920105,
      "learning_rate": 3.858823529411765e-05,
      "loss": 1.6141,
      "step": 1940
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7137335538864136,
      "learning_rate": 3.8529411764705886e-05,
      "loss": 1.5344,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8573613166809082,
      "learning_rate": 3.847058823529412e-05,
      "loss": 1.4194,
      "step": 1960
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.713721752166748,
      "learning_rate": 3.841176470588235e-05,
      "loss": 1.7601,
      "step": 1970
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.61387038230896,
      "learning_rate": 3.835294117647059e-05,
      "loss": 2.3021,
      "step": 1980
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.510282039642334,
      "learning_rate": 3.8294117647058826e-05,
      "loss": 1.9956,
      "step": 1990
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.722810745239258,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 1.9148,
      "step": 2000
    },
    {
      "epoch": 0.26,
      "eval_bleu-4": 0.007352092261144994,
      "eval_rouge-1": 15.163063999999999,
      "eval_rouge-2": 2.525064,
      "eval_rouge-l": 8.606603999999999,
      "eval_runtime": 782.1357,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 2000
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.468543767929077,
      "learning_rate": 3.81764705882353e-05,
      "loss": 1.5215,
      "step": 2010
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5896573066711426,
      "learning_rate": 3.811764705882353e-05,
      "loss": 1.9634,
      "step": 2020
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9104920625686646,
      "learning_rate": 3.805882352941177e-05,
      "loss": 1.9394,
      "step": 2030
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.058467149734497,
      "learning_rate": 3.8e-05,
      "loss": 1.9284,
      "step": 2040
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8718152046203613,
      "learning_rate": 3.794117647058824e-05,
      "loss": 2.1773,
      "step": 2050
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.121635913848877,
      "learning_rate": 3.7882352941176475e-05,
      "loss": 1.4497,
      "step": 2060
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9446643590927124,
      "learning_rate": 3.7823529411764705e-05,
      "loss": 1.6185,
      "step": 2070
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5567731857299805,
      "learning_rate": 3.776470588235294e-05,
      "loss": 1.8375,
      "step": 2080
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8681668043136597,
      "learning_rate": 3.770588235294118e-05,
      "loss": 1.6308,
      "step": 2090
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2197656631469727,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 1.943,
      "step": 2100
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.881116271018982,
      "learning_rate": 3.7588235294117645e-05,
      "loss": 1.4159,
      "step": 2110
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2873406410217285,
      "learning_rate": 3.752941176470588e-05,
      "loss": 2.128,
      "step": 2120
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3979103565216064,
      "learning_rate": 3.747058823529412e-05,
      "loss": 1.8648,
      "step": 2130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0728256702423096,
      "learning_rate": 3.7411764705882355e-05,
      "loss": 1.8529,
      "step": 2140
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1754372119903564,
      "learning_rate": 3.735294117647059e-05,
      "loss": 2.1254,
      "step": 2150
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.388080358505249,
      "learning_rate": 3.729411764705882e-05,
      "loss": 2.0856,
      "step": 2160
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.305142879486084,
      "learning_rate": 3.7235294117647065e-05,
      "loss": 1.9888,
      "step": 2170
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.673713445663452,
      "learning_rate": 3.7176470588235295e-05,
      "loss": 1.2274,
      "step": 2180
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1564624309539795,
      "learning_rate": 3.711764705882353e-05,
      "loss": 1.5416,
      "step": 2190
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9353389739990234,
      "learning_rate": 3.705882352941177e-05,
      "loss": 1.9027,
      "step": 2200
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.773437738418579,
      "learning_rate": 3.7e-05,
      "loss": 2.2377,
      "step": 2210
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0789082050323486,
      "learning_rate": 3.6941176470588235e-05,
      "loss": 1.6267,
      "step": 2220
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.8535796403884888,
      "learning_rate": 3.688235294117647e-05,
      "loss": 1.4833,
      "step": 2230
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7043330669403076,
      "learning_rate": 3.682352941176471e-05,
      "loss": 2.071,
      "step": 2240
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.3449292182922363,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.8475,
      "step": 2250
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4246346950531006,
      "learning_rate": 3.670588235294118e-05,
      "loss": 1.8328,
      "step": 2260
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1732139587402344,
      "learning_rate": 3.664705882352941e-05,
      "loss": 1.6236,
      "step": 2270
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7404873371124268,
      "learning_rate": 3.658823529411765e-05,
      "loss": 2.3478,
      "step": 2280
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.9458601474761963,
      "learning_rate": 3.6529411764705885e-05,
      "loss": 2.0789,
      "step": 2290
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7248296737670898,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 1.2653,
      "step": 2300
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.033937454223633,
      "learning_rate": 3.641176470588236e-05,
      "loss": 1.6143,
      "step": 2310
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9992233514785767,
      "learning_rate": 3.635294117647059e-05,
      "loss": 1.6457,
      "step": 2320
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7832584381103516,
      "learning_rate": 3.6294117647058824e-05,
      "loss": 2.324,
      "step": 2330
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.680030107498169,
      "learning_rate": 3.623529411764706e-05,
      "loss": 1.3203,
      "step": 2340
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0794899463653564,
      "learning_rate": 3.61764705882353e-05,
      "loss": 1.6604,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.57136070728302,
      "learning_rate": 3.6117647058823534e-05,
      "loss": 2.1184,
      "step": 2360
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9183681011199951,
      "learning_rate": 3.6058823529411764e-05,
      "loss": 1.2426,
      "step": 2370
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.8155035972595215,
      "learning_rate": 3.6e-05,
      "loss": 2.0003,
      "step": 2380
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.3117778301239014,
      "learning_rate": 3.594117647058824e-05,
      "loss": 2.0313,
      "step": 2390
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7839088439941406,
      "learning_rate": 3.5882352941176474e-05,
      "loss": 1.6962,
      "step": 2400
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.450000762939453,
      "learning_rate": 3.5823529411764704e-05,
      "loss": 1.5125,
      "step": 2410
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.6440720558166504,
      "learning_rate": 3.576470588235295e-05,
      "loss": 1.8233,
      "step": 2420
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.423382520675659,
      "learning_rate": 3.570588235294118e-05,
      "loss": 1.4507,
      "step": 2430
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.368068218231201,
      "learning_rate": 3.5647058823529414e-05,
      "loss": 2.4774,
      "step": 2440
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7364857196807861,
      "learning_rate": 3.558823529411765e-05,
      "loss": 1.9423,
      "step": 2450
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.179574012756348,
      "learning_rate": 3.552941176470588e-05,
      "loss": 1.2866,
      "step": 2460
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6034932136535645,
      "learning_rate": 3.5470588235294124e-05,
      "loss": 1.2228,
      "step": 2470
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5666322708129883,
      "learning_rate": 3.5411764705882354e-05,
      "loss": 1.9043,
      "step": 2480
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.817185878753662,
      "learning_rate": 3.535294117647059e-05,
      "loss": 1.8711,
      "step": 2490
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4493463039398193,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.9721,
      "step": 2500
    },
    {
      "epoch": 0.32,
      "eval_bleu-4": 0.0061998258956323425,
      "eval_rouge-1": 14.965072,
      "eval_rouge-2": 2.4639860000000002,
      "eval_rouge-l": 8.143062,
      "eval_runtime": 758.1176,
      "eval_samples_per_second": 0.066,
      "eval_steps_per_second": 0.005,
      "step": 2500
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2134475708007812,
      "learning_rate": 3.5235294117647064e-05,
      "loss": 1.6099,
      "step": 2510
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2021071910858154,
      "learning_rate": 3.5176470588235294e-05,
      "loss": 1.3881,
      "step": 2520
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1232693195343018,
      "learning_rate": 3.511764705882353e-05,
      "loss": 1.6546,
      "step": 2530
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.108617067337036,
      "learning_rate": 3.505882352941177e-05,
      "loss": 1.8089,
      "step": 2540
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.071486473083496,
      "learning_rate": 3.5e-05,
      "loss": 1.3186,
      "step": 2550
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.836077928543091,
      "learning_rate": 3.494117647058824e-05,
      "loss": 1.3649,
      "step": 2560
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.297325611114502,
      "learning_rate": 3.488235294117647e-05,
      "loss": 2.0222,
      "step": 2570
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.902653932571411,
      "learning_rate": 3.482352941176471e-05,
      "loss": 1.5175,
      "step": 2580
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.01723051071167,
      "learning_rate": 3.4764705882352944e-05,
      "loss": 1.4074,
      "step": 2590
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3298861980438232,
      "learning_rate": 3.470588235294118e-05,
      "loss": 1.8981,
      "step": 2600
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.603602170944214,
      "learning_rate": 3.464705882352942e-05,
      "loss": 1.9181,
      "step": 2610
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.994647741317749,
      "learning_rate": 3.458823529411765e-05,
      "loss": 1.6716,
      "step": 2620
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.539877414703369,
      "learning_rate": 3.4529411764705883e-05,
      "loss": 1.7304,
      "step": 2630
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.6402556896209717,
      "learning_rate": 3.447058823529412e-05,
      "loss": 1.6744,
      "step": 2640
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.082094669342041,
      "learning_rate": 3.441176470588236e-05,
      "loss": 1.4779,
      "step": 2650
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.156879186630249,
      "learning_rate": 3.4352941176470587e-05,
      "loss": 1.8866,
      "step": 2660
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.1617202758789062,
      "learning_rate": 3.429411764705882e-05,
      "loss": 1.8164,
      "step": 2670
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.369626760482788,
      "learning_rate": 3.423529411764706e-05,
      "loss": 1.5799,
      "step": 2680
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.204664945602417,
      "learning_rate": 3.417647058823529e-05,
      "loss": 2.4022,
      "step": 2690
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.1758205890655518,
      "learning_rate": 3.411764705882353e-05,
      "loss": 1.9857,
      "step": 2700
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.2973663806915283,
      "learning_rate": 3.405882352941176e-05,
      "loss": 1.4774,
      "step": 2710
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.787308692932129,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.7955,
      "step": 2720
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.1035563945770264,
      "learning_rate": 3.3941176470588236e-05,
      "loss": 1.4788,
      "step": 2730
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.386037588119507,
      "learning_rate": 3.388235294117647e-05,
      "loss": 1.3433,
      "step": 2740
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.6990861892700195,
      "learning_rate": 3.382352941176471e-05,
      "loss": 1.5525,
      "step": 2750
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3942036628723145,
      "learning_rate": 3.376470588235294e-05,
      "loss": 2.2214,
      "step": 2760
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.328122138977051,
      "learning_rate": 3.3705882352941176e-05,
      "loss": 1.552,
      "step": 2770
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3242127895355225,
      "learning_rate": 3.364705882352941e-05,
      "loss": 1.5241,
      "step": 2780
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.5346767902374268,
      "learning_rate": 3.358823529411765e-05,
      "loss": 1.6094,
      "step": 2790
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.3012516498565674,
      "learning_rate": 3.352941176470588e-05,
      "loss": 1.7354,
      "step": 2800
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.4818127155303955,
      "learning_rate": 3.347058823529412e-05,
      "loss": 2.1555,
      "step": 2810
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.7537732124328613,
      "learning_rate": 3.341176470588235e-05,
      "loss": 2.043,
      "step": 2820
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6539998054504395,
      "learning_rate": 3.335294117647059e-05,
      "loss": 1.7431,
      "step": 2830
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.231738328933716,
      "learning_rate": 3.3294117647058826e-05,
      "loss": 1.5274,
      "step": 2840
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.149749517440796,
      "learning_rate": 3.3235294117647056e-05,
      "loss": 1.5026,
      "step": 2850
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0494296550750732,
      "learning_rate": 3.31764705882353e-05,
      "loss": 2.1838,
      "step": 2860
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9731146097183228,
      "learning_rate": 3.311764705882353e-05,
      "loss": 1.7802,
      "step": 2870
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8408620357513428,
      "learning_rate": 3.3058823529411766e-05,
      "loss": 1.1811,
      "step": 2880
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1161577701568604,
      "learning_rate": 3.3e-05,
      "loss": 1.3205,
      "step": 2890
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.365225315093994,
      "learning_rate": 3.294117647058824e-05,
      "loss": 1.498,
      "step": 2900
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.881964921951294,
      "learning_rate": 3.288235294117647e-05,
      "loss": 2.1128,
      "step": 2910
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.719506025314331,
      "learning_rate": 3.2823529411764706e-05,
      "loss": 1.4171,
      "step": 2920
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.4906790256500244,
      "learning_rate": 3.276470588235294e-05,
      "loss": 1.3601,
      "step": 2930
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7030961513519287,
      "learning_rate": 3.270588235294118e-05,
      "loss": 1.895,
      "step": 2940
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.264988422393799,
      "learning_rate": 3.2647058823529416e-05,
      "loss": 2.0202,
      "step": 2950
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7987418174743652,
      "learning_rate": 3.2588235294117646e-05,
      "loss": 2.1535,
      "step": 2960
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.3476946353912354,
      "learning_rate": 3.252941176470589e-05,
      "loss": 1.4715,
      "step": 2970
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.9451916217803955,
      "learning_rate": 3.247058823529412e-05,
      "loss": 2.4075,
      "step": 2980
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.436126708984375,
      "learning_rate": 3.2411764705882356e-05,
      "loss": 1.7831,
      "step": 2990
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.074416399002075,
      "learning_rate": 3.235294117647059e-05,
      "loss": 1.062,
      "step": 3000
    },
    {
      "epoch": 0.39,
      "eval_bleu-4": 0.005826690054826956,
      "eval_rouge-1": 14.001019999999999,
      "eval_rouge-2": 2.3419879999999997,
      "eval_rouge-l": 7.307937999999999,
      "eval_runtime": 762.1024,
      "eval_samples_per_second": 0.066,
      "eval_steps_per_second": 0.005,
      "step": 3000
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.691042184829712,
      "learning_rate": 3.229411764705882e-05,
      "loss": 2.2719,
      "step": 3010
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7722816467285156,
      "learning_rate": 3.223529411764706e-05,
      "loss": 1.5644,
      "step": 3020
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.632524013519287,
      "learning_rate": 3.2176470588235295e-05,
      "loss": 1.5764,
      "step": 3030
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.673659086227417,
      "learning_rate": 3.211764705882353e-05,
      "loss": 1.6521,
      "step": 3040
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.392922878265381,
      "learning_rate": 3.205882352941177e-05,
      "loss": 2.2139,
      "step": 3050
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2451045513153076,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.7228,
      "step": 3060
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.53084659576416,
      "learning_rate": 3.1941176470588235e-05,
      "loss": 1.7447,
      "step": 3070
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.699586868286133,
      "learning_rate": 3.188235294117647e-05,
      "loss": 1.5692,
      "step": 3080
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.5168657302856445,
      "learning_rate": 3.182352941176471e-05,
      "loss": 1.3039,
      "step": 3090
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.56040620803833,
      "learning_rate": 3.176470588235294e-05,
      "loss": 1.6238,
      "step": 3100
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.944211721420288,
      "learning_rate": 3.170588235294118e-05,
      "loss": 1.696,
      "step": 3110
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.6964914798736572,
      "learning_rate": 3.164705882352941e-05,
      "loss": 2.1916,
      "step": 3120
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5651791095733643,
      "learning_rate": 3.158823529411765e-05,
      "loss": 1.97,
      "step": 3130
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.657733917236328,
      "learning_rate": 3.1529411764705885e-05,
      "loss": 1.6127,
      "step": 3140
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.64947247505188,
      "learning_rate": 3.147058823529412e-05,
      "loss": 1.3326,
      "step": 3150
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.544785499572754,
      "learning_rate": 3.141176470588236e-05,
      "loss": 1.7461,
      "step": 3160
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8508881330490112,
      "learning_rate": 3.135294117647059e-05,
      "loss": 1.8184,
      "step": 3170
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.8224034309387207,
      "learning_rate": 3.1294117647058825e-05,
      "loss": 1.8938,
      "step": 3180
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.906782627105713,
      "learning_rate": 3.123529411764706e-05,
      "loss": 2.0716,
      "step": 3190
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.4483282566070557,
      "learning_rate": 3.11764705882353e-05,
      "loss": 1.9874,
      "step": 3200
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.664111375808716,
      "learning_rate": 3.111764705882353e-05,
      "loss": 1.6729,
      "step": 3210
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.34389591217041,
      "learning_rate": 3.1058823529411765e-05,
      "loss": 2.0371,
      "step": 3220
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.9973154067993164,
      "learning_rate": 3.1e-05,
      "loss": 1.9267,
      "step": 3230
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4099602699279785,
      "learning_rate": 3.094117647058823e-05,
      "loss": 2.372,
      "step": 3240
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.662079095840454,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 1.5403,
      "step": 3250
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.90064537525177,
      "learning_rate": 3.0823529411764705e-05,
      "loss": 1.5634,
      "step": 3260
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.3251538276672363,
      "learning_rate": 3.076470588235294e-05,
      "loss": 2.2486,
      "step": 3270
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.4151840209960938,
      "learning_rate": 3.070588235294118e-05,
      "loss": 1.7059,
      "step": 3280
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.8048341274261475,
      "learning_rate": 3.0647058823529415e-05,
      "loss": 1.7984,
      "step": 3290
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8354573249816895,
      "learning_rate": 3.058823529411765e-05,
      "loss": 1.0555,
      "step": 3300
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.099708318710327,
      "learning_rate": 3.052941176470588e-05,
      "loss": 1.9228,
      "step": 3310
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5065805912017822,
      "learning_rate": 3.0470588235294118e-05,
      "loss": 1.52,
      "step": 3320
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1178712844848633,
      "learning_rate": 3.0411764705882358e-05,
      "loss": 1.2482,
      "step": 3330
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.271554708480835,
      "learning_rate": 3.035294117647059e-05,
      "loss": 1.8305,
      "step": 3340
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8019886016845703,
      "learning_rate": 3.0294117647058824e-05,
      "loss": 1.8549,
      "step": 3350
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.6712963581085205,
      "learning_rate": 3.023529411764706e-05,
      "loss": 1.7245,
      "step": 3360
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5783627033233643,
      "learning_rate": 3.0176470588235294e-05,
      "loss": 1.7918,
      "step": 3370
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.467336893081665,
      "learning_rate": 3.0117647058823527e-05,
      "loss": 1.9169,
      "step": 3380
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9931050539016724,
      "learning_rate": 3.0058823529411767e-05,
      "loss": 1.2207,
      "step": 3390
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.8606836795806885,
      "learning_rate": 3e-05,
      "loss": 1.5132,
      "step": 3400
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3032968044281006,
      "learning_rate": 2.994117647058824e-05,
      "loss": 1.8237,
      "step": 3410
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3405494689941406,
      "learning_rate": 2.9882352941176474e-05,
      "loss": 2.2718,
      "step": 3420
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3432300090789795,
      "learning_rate": 2.9823529411764707e-05,
      "loss": 1.6407,
      "step": 3430
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.420119285583496,
      "learning_rate": 2.9764705882352944e-05,
      "loss": 2.0881,
      "step": 3440
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6728694438934326,
      "learning_rate": 2.9705882352941177e-05,
      "loss": 1.7052,
      "step": 3450
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.0391194820404053,
      "learning_rate": 2.964705882352941e-05,
      "loss": 1.5705,
      "step": 3460
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4242095947265625,
      "learning_rate": 2.958823529411765e-05,
      "loss": 1.853,
      "step": 3470
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.1080548763275146,
      "learning_rate": 2.9529411764705884e-05,
      "loss": 2.1794,
      "step": 3480
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3734452724456787,
      "learning_rate": 2.9470588235294117e-05,
      "loss": 2.0624,
      "step": 3490
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.275162696838379,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 2.2051,
      "step": 3500
    },
    {
      "epoch": 0.45,
      "eval_bleu-4": 0.006183683822211395,
      "eval_rouge-1": 14.37837,
      "eval_rouge-2": 2.007916,
      "eval_rouge-l": 8.076936,
      "eval_runtime": 781.5516,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 3500
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.0019350051879883,
      "learning_rate": 2.9352941176470587e-05,
      "loss": 1.7521,
      "step": 3510
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6137752532958984,
      "learning_rate": 2.9294117647058827e-05,
      "loss": 1.9461,
      "step": 3520
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.687157392501831,
      "learning_rate": 2.923529411764706e-05,
      "loss": 2.2811,
      "step": 3530
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.545034885406494,
      "learning_rate": 2.9176470588235294e-05,
      "loss": 2.3139,
      "step": 3540
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.4498558044433594,
      "learning_rate": 2.9117647058823534e-05,
      "loss": 1.8929,
      "step": 3550
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.6607635021209717,
      "learning_rate": 2.9058823529411767e-05,
      "loss": 1.9195,
      "step": 3560
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.3709282875061035,
      "learning_rate": 2.9e-05,
      "loss": 2.0735,
      "step": 3570
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.2585339546203613,
      "learning_rate": 2.8941176470588237e-05,
      "loss": 2.1226,
      "step": 3580
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.813753128051758,
      "learning_rate": 2.888235294117647e-05,
      "loss": 1.6876,
      "step": 3590
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.084279775619507,
      "learning_rate": 2.8823529411764703e-05,
      "loss": 1.5752,
      "step": 3600
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.7649948596954346,
      "learning_rate": 2.8764705882352943e-05,
      "loss": 1.4494,
      "step": 3610
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.4508564472198486,
      "learning_rate": 2.8705882352941177e-05,
      "loss": 1.4013,
      "step": 3620
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.7426912784576416,
      "learning_rate": 2.8647058823529417e-05,
      "loss": 1.6947,
      "step": 3630
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.6257002353668213,
      "learning_rate": 2.858823529411765e-05,
      "loss": 1.7141,
      "step": 3640
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.954785108566284,
      "learning_rate": 2.8529411764705883e-05,
      "loss": 1.6978,
      "step": 3650
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.9215872287750244,
      "learning_rate": 2.847058823529412e-05,
      "loss": 2.0134,
      "step": 3660
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3349010944366455,
      "learning_rate": 2.8411764705882353e-05,
      "loss": 1.5868,
      "step": 3670
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.667515754699707,
      "learning_rate": 2.8352941176470586e-05,
      "loss": 1.7628,
      "step": 3680
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.315546989440918,
      "learning_rate": 2.8294117647058826e-05,
      "loss": 1.9619,
      "step": 3690
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.226397752761841,
      "learning_rate": 2.823529411764706e-05,
      "loss": 1.9047,
      "step": 3700
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.9107918739318848,
      "learning_rate": 2.8176470588235293e-05,
      "loss": 1.5091,
      "step": 3710
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.7928597927093506,
      "learning_rate": 2.8117647058823533e-05,
      "loss": 1.6495,
      "step": 3720
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2472410202026367,
      "learning_rate": 2.8058823529411766e-05,
      "loss": 1.3882,
      "step": 3730
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.418612480163574,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.7292,
      "step": 3740
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.9657835960388184,
      "learning_rate": 2.7941176470588236e-05,
      "loss": 1.5707,
      "step": 3750
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.52457332611084,
      "learning_rate": 2.788235294117647e-05,
      "loss": 1.4157,
      "step": 3760
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.834430456161499,
      "learning_rate": 2.782352941176471e-05,
      "loss": 1.7221,
      "step": 3770
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.263465404510498,
      "learning_rate": 2.7764705882352943e-05,
      "loss": 1.8306,
      "step": 3780
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.7351746559143066,
      "learning_rate": 2.7705882352941176e-05,
      "loss": 1.8278,
      "step": 3790
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.775622844696045,
      "learning_rate": 2.7647058823529416e-05,
      "loss": 2.0187,
      "step": 3800
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.464895248413086,
      "learning_rate": 2.758823529411765e-05,
      "loss": 1.4976,
      "step": 3810
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.3576977252960205,
      "learning_rate": 2.7529411764705883e-05,
      "loss": 1.6106,
      "step": 3820
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.3792364597320557,
      "learning_rate": 2.747058823529412e-05,
      "loss": 1.8564,
      "step": 3830
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.4017629623413086,
      "learning_rate": 2.7411764705882353e-05,
      "loss": 1.5357,
      "step": 3840
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.053668975830078,
      "learning_rate": 2.7352941176470593e-05,
      "loss": 1.9188,
      "step": 3850
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.172117233276367,
      "learning_rate": 2.7294117647058826e-05,
      "loss": 1.8441,
      "step": 3860
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.7068488597869873,
      "learning_rate": 2.723529411764706e-05,
      "loss": 1.2229,
      "step": 3870
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.033867359161377,
      "learning_rate": 2.71764705882353e-05,
      "loss": 1.2482,
      "step": 3880
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.6827285289764404,
      "learning_rate": 2.7117647058823532e-05,
      "loss": 1.7258,
      "step": 3890
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.43342924118042,
      "learning_rate": 2.7058823529411766e-05,
      "loss": 1.5935,
      "step": 3900
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.184065818786621,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.6443,
      "step": 3910
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.955944299697876,
      "learning_rate": 2.6941176470588236e-05,
      "loss": 1.6234,
      "step": 3920
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.511959552764893,
      "learning_rate": 2.688235294117647e-05,
      "loss": 1.4764,
      "step": 3930
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.398221015930176,
      "learning_rate": 2.682352941176471e-05,
      "loss": 1.6477,
      "step": 3940
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.5108675956726074,
      "learning_rate": 2.6764705882352942e-05,
      "loss": 1.7984,
      "step": 3950
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.0986456871032715,
      "learning_rate": 2.6705882352941175e-05,
      "loss": 1.6021,
      "step": 3960
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.678870916366577,
      "learning_rate": 2.6647058823529416e-05,
      "loss": 1.8313,
      "step": 3970
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.5794286727905273,
      "learning_rate": 2.658823529411765e-05,
      "loss": 1.4709,
      "step": 3980
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.7766332626342773,
      "learning_rate": 2.6529411764705885e-05,
      "loss": 2.0364,
      "step": 3990
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.6944823265075684,
      "learning_rate": 2.647058823529412e-05,
      "loss": 2.0123,
      "step": 4000
    },
    {
      "epoch": 0.52,
      "eval_bleu-4": 0.007269425695299256,
      "eval_rouge-1": 14.945988,
      "eval_rouge-2": 2.143516,
      "eval_rouge-l": 8.348448,
      "eval_runtime": 781.8637,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 4000
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.3024773597717285,
      "learning_rate": 2.6411764705882352e-05,
      "loss": 1.7821,
      "step": 4010
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.5390167236328125,
      "learning_rate": 2.6352941176470592e-05,
      "loss": 2.1507,
      "step": 4020
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.448000431060791,
      "learning_rate": 2.6294117647058825e-05,
      "loss": 1.7838,
      "step": 4030
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.408801555633545,
      "learning_rate": 2.623529411764706e-05,
      "loss": 1.2938,
      "step": 4040
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.634397506713867,
      "learning_rate": 2.6176470588235295e-05,
      "loss": 1.3714,
      "step": 4050
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.429802417755127,
      "learning_rate": 2.611764705882353e-05,
      "loss": 1.6446,
      "step": 4060
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.180614948272705,
      "learning_rate": 2.6058823529411762e-05,
      "loss": 1.8221,
      "step": 4070
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.8028011322021484,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.7807,
      "step": 4080
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.6470675468444824,
      "learning_rate": 2.5941176470588235e-05,
      "loss": 1.5142,
      "step": 4090
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.690330743789673,
      "learning_rate": 2.5882352941176475e-05,
      "loss": 1.866,
      "step": 4100
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.2714712619781494,
      "learning_rate": 2.582352941176471e-05,
      "loss": 1.5678,
      "step": 4110
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.106243371963501,
      "learning_rate": 2.576470588235294e-05,
      "loss": 1.5957,
      "step": 4120
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.6641013622283936,
      "learning_rate": 2.5705882352941178e-05,
      "loss": 1.5914,
      "step": 4130
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.5064268112182617,
      "learning_rate": 2.564705882352941e-05,
      "loss": 1.773,
      "step": 4140
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.146726369857788,
      "learning_rate": 2.5588235294117645e-05,
      "loss": 1.7432,
      "step": 4150
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.830839157104492,
      "learning_rate": 2.5529411764705885e-05,
      "loss": 1.2781,
      "step": 4160
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5588369369506836,
      "learning_rate": 2.5470588235294118e-05,
      "loss": 1.5989,
      "step": 4170
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.39617919921875,
      "learning_rate": 2.541176470588235e-05,
      "loss": 1.5804,
      "step": 4180
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.4742677211761475,
      "learning_rate": 2.535294117647059e-05,
      "loss": 1.7613,
      "step": 4190
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5041344165802,
      "learning_rate": 2.5294117647058825e-05,
      "loss": 1.6805,
      "step": 4200
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.4107372760772705,
      "learning_rate": 2.523529411764706e-05,
      "loss": 1.6809,
      "step": 4210
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.4860148429870605,
      "learning_rate": 2.5176470588235295e-05,
      "loss": 1.7907,
      "step": 4220
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.606945037841797,
      "learning_rate": 2.5117647058823528e-05,
      "loss": 1.7915,
      "step": 4230
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.176694631576538,
      "learning_rate": 2.5058823529411768e-05,
      "loss": 1.9858,
      "step": 4240
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.3549351692199707,
      "learning_rate": 2.5e-05,
      "loss": 1.6737,
      "step": 4250
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.0564091205596924,
      "learning_rate": 2.4941176470588238e-05,
      "loss": 1.9555,
      "step": 4260
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1015002727508545,
      "learning_rate": 2.488235294117647e-05,
      "loss": 1.6377,
      "step": 4270
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.5606863498687744,
      "learning_rate": 2.4823529411764708e-05,
      "loss": 1.8268,
      "step": 4280
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.213578462600708,
      "learning_rate": 2.476470588235294e-05,
      "loss": 1.9427,
      "step": 4290
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.7115094661712646,
      "learning_rate": 2.4705882352941178e-05,
      "loss": 1.8845,
      "step": 4300
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.213651418685913,
      "learning_rate": 2.464705882352941e-05,
      "loss": 1.3132,
      "step": 4310
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.6852660179138184,
      "learning_rate": 2.4588235294117648e-05,
      "loss": 1.7122,
      "step": 4320
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3212716579437256,
      "learning_rate": 2.4529411764705884e-05,
      "loss": 1.9625,
      "step": 4330
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.0120110511779785,
      "learning_rate": 2.447058823529412e-05,
      "loss": 1.6059,
      "step": 4340
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.3126769065856934,
      "learning_rate": 2.4411764705882354e-05,
      "loss": 2.0082,
      "step": 4350
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.68652606010437,
      "learning_rate": 2.435294117647059e-05,
      "loss": 1.514,
      "step": 4360
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.849842071533203,
      "learning_rate": 2.4294117647058824e-05,
      "loss": 1.7764,
      "step": 4370
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.5186355113983154,
      "learning_rate": 2.4235294117647057e-05,
      "loss": 1.768,
      "step": 4380
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.2741692066192627,
      "learning_rate": 2.4176470588235294e-05,
      "loss": 1.7965,
      "step": 4390
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.309420585632324,
      "learning_rate": 2.411764705882353e-05,
      "loss": 1.7978,
      "step": 4400
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.3556244373321533,
      "learning_rate": 2.4058823529411767e-05,
      "loss": 1.6318,
      "step": 4410
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8465551137924194,
      "learning_rate": 2.4e-05,
      "loss": 1.781,
      "step": 4420
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.7900195121765137,
      "learning_rate": 2.3941176470588237e-05,
      "loss": 1.6455,
      "step": 4430
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.6161577701568604,
      "learning_rate": 2.3882352941176474e-05,
      "loss": 1.5896,
      "step": 4440
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.7873175144195557,
      "learning_rate": 2.3823529411764707e-05,
      "loss": 1.5413,
      "step": 4450
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3784303665161133,
      "learning_rate": 2.376470588235294e-05,
      "loss": 1.4856,
      "step": 4460
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7715649604797363,
      "learning_rate": 2.3705882352941177e-05,
      "loss": 1.2119,
      "step": 4470
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.939324378967285,
      "learning_rate": 2.3647058823529414e-05,
      "loss": 1.7737,
      "step": 4480
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.6459078788757324,
      "learning_rate": 2.3588235294117647e-05,
      "loss": 1.3446,
      "step": 4490
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.3015716075897217,
      "learning_rate": 2.3529411764705884e-05,
      "loss": 1.891,
      "step": 4500
    },
    {
      "epoch": 0.58,
      "eval_bleu-4": 0.005122022801820923,
      "eval_rouge-1": 14.408248,
      "eval_rouge-2": 2.0697200000000002,
      "eval_rouge-l": 6.792063999999999,
      "eval_runtime": 781.8242,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 4500
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.6794567108154297,
      "learning_rate": 2.347058823529412e-05,
      "loss": 1.5017,
      "step": 4510
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.5598061084747314,
      "learning_rate": 2.3411764705882354e-05,
      "loss": 1.9549,
      "step": 4520
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7387406826019287,
      "learning_rate": 2.3352941176470587e-05,
      "loss": 1.0394,
      "step": 4530
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.050057888031006,
      "learning_rate": 2.3294117647058824e-05,
      "loss": 1.7334,
      "step": 4540
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.9370546340942383,
      "learning_rate": 2.323529411764706e-05,
      "loss": 1.5729,
      "step": 4550
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.025288105010986,
      "learning_rate": 2.3176470588235293e-05,
      "loss": 1.7305,
      "step": 4560
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.803328514099121,
      "learning_rate": 2.311764705882353e-05,
      "loss": 1.7884,
      "step": 4570
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.550598382949829,
      "learning_rate": 2.3058823529411767e-05,
      "loss": 1.1688,
      "step": 4580
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.9474334716796875,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 2.1677,
      "step": 4590
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.1400396823883057,
      "learning_rate": 2.2941176470588237e-05,
      "loss": 1.9547,
      "step": 4600
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.2554969787597656,
      "learning_rate": 2.288235294117647e-05,
      "loss": 1.4588,
      "step": 4610
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.503295660018921,
      "learning_rate": 2.2823529411764707e-05,
      "loss": 1.8371,
      "step": 4620
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.8498308658599854,
      "learning_rate": 2.2764705882352943e-05,
      "loss": 1.7965,
      "step": 4630
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.393179416656494,
      "learning_rate": 2.2705882352941177e-05,
      "loss": 1.5442,
      "step": 4640
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3167002201080322,
      "learning_rate": 2.2647058823529413e-05,
      "loss": 1.3305,
      "step": 4650
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.2095465660095215,
      "learning_rate": 2.258823529411765e-05,
      "loss": 1.7473,
      "step": 4660
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.164872884750366,
      "learning_rate": 2.2529411764705883e-05,
      "loss": 1.2464,
      "step": 4670
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.5184669494628906,
      "learning_rate": 2.247058823529412e-05,
      "loss": 2.1212,
      "step": 4680
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.8225176334381104,
      "learning_rate": 2.2411764705882353e-05,
      "loss": 1.6212,
      "step": 4690
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.678123950958252,
      "learning_rate": 2.235294117647059e-05,
      "loss": 1.8179,
      "step": 4700
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.7630562782287598,
      "learning_rate": 2.2294117647058823e-05,
      "loss": 1.5174,
      "step": 4710
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.5695064067840576,
      "learning_rate": 2.223529411764706e-05,
      "loss": 2.009,
      "step": 4720
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.6529979705810547,
      "learning_rate": 2.2176470588235296e-05,
      "loss": 2.079,
      "step": 4730
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.13077712059021,
      "learning_rate": 2.2117647058823533e-05,
      "loss": 1.1971,
      "step": 4740
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.295015335083008,
      "learning_rate": 2.2058823529411766e-05,
      "loss": 1.6783,
      "step": 4750
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.370802640914917,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.8273,
      "step": 4760
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.055879592895508,
      "learning_rate": 2.1941176470588236e-05,
      "loss": 2.212,
      "step": 4770
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.0875048637390137,
      "learning_rate": 2.188235294117647e-05,
      "loss": 1.936,
      "step": 4780
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.198650598526001,
      "learning_rate": 2.1823529411764706e-05,
      "loss": 1.4534,
      "step": 4790
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.223599672317505,
      "learning_rate": 2.1764705882352943e-05,
      "loss": 1.1085,
      "step": 4800
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.4878242015838623,
      "learning_rate": 2.170588235294118e-05,
      "loss": 1.7458,
      "step": 4810
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.82910680770874,
      "learning_rate": 2.1647058823529413e-05,
      "loss": 1.4701,
      "step": 4820
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.217355728149414,
      "learning_rate": 2.158823529411765e-05,
      "loss": 1.28,
      "step": 4830
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.9612035751342773,
      "learning_rate": 2.1529411764705882e-05,
      "loss": 1.8574,
      "step": 4840
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.392102003097534,
      "learning_rate": 2.1470588235294116e-05,
      "loss": 1.5161,
      "step": 4850
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9612268209457397,
      "learning_rate": 2.1411764705882352e-05,
      "loss": 1.9027,
      "step": 4860
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.112172842025757,
      "learning_rate": 2.135294117647059e-05,
      "loss": 1.9044,
      "step": 4870
    },
    {
      "epoch": 0.63,
      "grad_norm": 5.113216400146484,
      "learning_rate": 2.1294117647058826e-05,
      "loss": 1.819,
      "step": 4880
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.165492296218872,
      "learning_rate": 2.123529411764706e-05,
      "loss": 1.6179,
      "step": 4890
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.106410264968872,
      "learning_rate": 2.1176470588235296e-05,
      "loss": 1.7794,
      "step": 4900
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.729327917098999,
      "learning_rate": 2.1117647058823532e-05,
      "loss": 1.8269,
      "step": 4910
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0956807136535645,
      "learning_rate": 2.1058823529411766e-05,
      "loss": 1.5357,
      "step": 4920
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.3509323596954346,
      "learning_rate": 2.1e-05,
      "loss": 1.5831,
      "step": 4930
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.645031452178955,
      "learning_rate": 2.0941176470588235e-05,
      "loss": 1.7217,
      "step": 4940
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.2916789054870605,
      "learning_rate": 2.0882352941176472e-05,
      "loss": 1.6092,
      "step": 4950
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.687328338623047,
      "learning_rate": 2.0823529411764705e-05,
      "loss": 1.7,
      "step": 4960
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9561524391174316,
      "learning_rate": 2.0764705882352942e-05,
      "loss": 1.1764,
      "step": 4970
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.4556825160980225,
      "learning_rate": 2.070588235294118e-05,
      "loss": 1.8966,
      "step": 4980
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.031524658203125,
      "learning_rate": 2.0647058823529415e-05,
      "loss": 1.7435,
      "step": 4990
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.081523895263672,
      "learning_rate": 2.058823529411765e-05,
      "loss": 1.7901,
      "step": 5000
    },
    {
      "epoch": 0.64,
      "eval_bleu-4": 0.005514037889529181,
      "eval_rouge-1": 14.60913,
      "eval_rouge-2": 2.209642,
      "eval_rouge-l": 7.465881999999999,
      "eval_runtime": 781.9131,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 5000
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.240186929702759,
      "learning_rate": 2.0529411764705882e-05,
      "loss": 1.815,
      "step": 5010
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.0271477699279785,
      "learning_rate": 2.047058823529412e-05,
      "loss": 1.6317,
      "step": 5020
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.417872428894043,
      "learning_rate": 2.0411764705882355e-05,
      "loss": 1.6166,
      "step": 5030
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.27026104927063,
      "learning_rate": 2.035294117647059e-05,
      "loss": 2.0699,
      "step": 5040
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.2789523601531982,
      "learning_rate": 2.0294117647058825e-05,
      "loss": 1.0563,
      "step": 5050
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.9887025356292725,
      "learning_rate": 2.0235294117647062e-05,
      "loss": 2.0183,
      "step": 5060
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.572551965713501,
      "learning_rate": 2.0176470588235295e-05,
      "loss": 1.375,
      "step": 5070
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.812467336654663,
      "learning_rate": 2.011764705882353e-05,
      "loss": 1.5538,
      "step": 5080
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.9420580863952637,
      "learning_rate": 2.0058823529411765e-05,
      "loss": 2.0321,
      "step": 5090
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.5712673664093018,
      "learning_rate": 2e-05,
      "loss": 1.6501,
      "step": 5100
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.605679750442505,
      "learning_rate": 1.9941176470588235e-05,
      "loss": 1.0461,
      "step": 5110
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.81282377243042,
      "learning_rate": 1.988235294117647e-05,
      "loss": 1.8496,
      "step": 5120
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.765532970428467,
      "learning_rate": 1.9823529411764708e-05,
      "loss": 1.7745,
      "step": 5130
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.2284982204437256,
      "learning_rate": 1.976470588235294e-05,
      "loss": 1.8188,
      "step": 5140
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.697596788406372,
      "learning_rate": 1.9705882352941178e-05,
      "loss": 1.4807,
      "step": 5150
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6838736534118652,
      "learning_rate": 1.964705882352941e-05,
      "loss": 1.5693,
      "step": 5160
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.090315818786621,
      "learning_rate": 1.9588235294117648e-05,
      "loss": 1.3142,
      "step": 5170
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.201442718505859,
      "learning_rate": 1.952941176470588e-05,
      "loss": 1.4713,
      "step": 5180
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.75224232673645,
      "learning_rate": 1.9470588235294118e-05,
      "loss": 1.8167,
      "step": 5190
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.2269489765167236,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 1.3913,
      "step": 5200
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.9004628658294678,
      "learning_rate": 1.935294117647059e-05,
      "loss": 1.445,
      "step": 5210
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.4287548065185547,
      "learning_rate": 1.9294117647058825e-05,
      "loss": 1.6889,
      "step": 5220
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.444941520690918,
      "learning_rate": 1.923529411764706e-05,
      "loss": 2.2083,
      "step": 5230
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.2232279777526855,
      "learning_rate": 1.9176470588235294e-05,
      "loss": 1.5227,
      "step": 5240
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.3093583583831787,
      "learning_rate": 1.9117647058823528e-05,
      "loss": 1.4174,
      "step": 5250
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4699721336364746,
      "learning_rate": 1.9058823529411764e-05,
      "loss": 1.61,
      "step": 5260
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.760449171066284,
      "learning_rate": 1.9e-05,
      "loss": 1.6935,
      "step": 5270
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.758404016494751,
      "learning_rate": 1.8941176470588238e-05,
      "loss": 1.9464,
      "step": 5280
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.049327850341797,
      "learning_rate": 1.888235294117647e-05,
      "loss": 1.9482,
      "step": 5290
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.1878037452697754,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 1.7628,
      "step": 5300
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.105670213699341,
      "learning_rate": 1.876470588235294e-05,
      "loss": 1.1781,
      "step": 5310
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.7121100425720215,
      "learning_rate": 1.8705882352941178e-05,
      "loss": 1.9398,
      "step": 5320
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.963606119155884,
      "learning_rate": 1.864705882352941e-05,
      "loss": 2.0018,
      "step": 5330
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.5036089420318604,
      "learning_rate": 1.8588235294117647e-05,
      "loss": 1.7146,
      "step": 5340
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.175276756286621,
      "learning_rate": 1.8529411764705884e-05,
      "loss": 1.5913,
      "step": 5350
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1069865226745605,
      "learning_rate": 1.8470588235294117e-05,
      "loss": 1.0866,
      "step": 5360
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.2790675163269043,
      "learning_rate": 1.8411764705882354e-05,
      "loss": 1.1684,
      "step": 5370
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.4273674488067627,
      "learning_rate": 1.835294117647059e-05,
      "loss": 1.4356,
      "step": 5380
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1106176376342773,
      "learning_rate": 1.8294117647058824e-05,
      "loss": 1.1901,
      "step": 5390
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8303375244140625,
      "learning_rate": 1.8235294117647057e-05,
      "loss": 1.5174,
      "step": 5400
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.0895586013793945,
      "learning_rate": 1.8176470588235294e-05,
      "loss": 1.3194,
      "step": 5410
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.520711660385132,
      "learning_rate": 1.811764705882353e-05,
      "loss": 1.569,
      "step": 5420
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.567283868789673,
      "learning_rate": 1.8058823529411767e-05,
      "loss": 2.1086,
      "step": 5430
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.0502119064331055,
      "learning_rate": 1.8e-05,
      "loss": 1.5014,
      "step": 5440
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.8409037590026855,
      "learning_rate": 1.7941176470588237e-05,
      "loss": 1.5799,
      "step": 5450
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.250628471374512,
      "learning_rate": 1.7882352941176474e-05,
      "loss": 1.4343,
      "step": 5460
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.7616612911224365,
      "learning_rate": 1.7823529411764707e-05,
      "loss": 2.0304,
      "step": 5470
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.102123975753784,
      "learning_rate": 1.776470588235294e-05,
      "loss": 1.9191,
      "step": 5480
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6507844924926758,
      "learning_rate": 1.7705882352941177e-05,
      "loss": 1.3966,
      "step": 5490
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.563434600830078,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 1.6549,
      "step": 5500
    },
    {
      "epoch": 0.71,
      "eval_bleu-4": 0.006194936573317874,
      "eval_rouge-1": 15.421228000000001,
      "eval_rouge-2": 2.4176640000000003,
      "eval_rouge-l": 7.7384,
      "eval_runtime": 781.7374,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 5500
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.934279441833496,
      "learning_rate": 1.7588235294117647e-05,
      "loss": 1.74,
      "step": 5510
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.9902286529541016,
      "learning_rate": 1.7529411764705884e-05,
      "loss": 2.1871,
      "step": 5520
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.064059257507324,
      "learning_rate": 1.747058823529412e-05,
      "loss": 1.7901,
      "step": 5530
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.3440983295440674,
      "learning_rate": 1.7411764705882353e-05,
      "loss": 1.9892,
      "step": 5540
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.9815120697021484,
      "learning_rate": 1.735294117647059e-05,
      "loss": 2.0789,
      "step": 5550
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.37172269821167,
      "learning_rate": 1.7294117647058823e-05,
      "loss": 1.3726,
      "step": 5560
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.6990163326263428,
      "learning_rate": 1.723529411764706e-05,
      "loss": 2.141,
      "step": 5570
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.914520263671875,
      "learning_rate": 1.7176470588235293e-05,
      "loss": 1.5498,
      "step": 5580
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.150459051132202,
      "learning_rate": 1.711764705882353e-05,
      "loss": 1.1625,
      "step": 5590
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.7879903316497803,
      "learning_rate": 1.7058823529411767e-05,
      "loss": 1.731,
      "step": 5600
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.3868415355682373,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.531,
      "step": 5610
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1222760677337646,
      "learning_rate": 1.6941176470588237e-05,
      "loss": 1.6818,
      "step": 5620
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.6209604740142822,
      "learning_rate": 1.688235294117647e-05,
      "loss": 1.7597,
      "step": 5630
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.783409833908081,
      "learning_rate": 1.6823529411764706e-05,
      "loss": 1.6615,
      "step": 5640
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.078462600708008,
      "learning_rate": 1.676470588235294e-05,
      "loss": 1.3081,
      "step": 5650
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.635488271713257,
      "learning_rate": 1.6705882352941176e-05,
      "loss": 1.7003,
      "step": 5660
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.17094349861145,
      "learning_rate": 1.6647058823529413e-05,
      "loss": 1.3549,
      "step": 5670
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.100660800933838,
      "learning_rate": 1.658823529411765e-05,
      "loss": 1.788,
      "step": 5680
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.6479170322418213,
      "learning_rate": 1.6529411764705883e-05,
      "loss": 1.4441,
      "step": 5690
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.077799081802368,
      "learning_rate": 1.647058823529412e-05,
      "loss": 1.0634,
      "step": 5700
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.783637046813965,
      "learning_rate": 1.6411764705882353e-05,
      "loss": 1.8825,
      "step": 5710
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.372920036315918,
      "learning_rate": 1.635294117647059e-05,
      "loss": 1.1557,
      "step": 5720
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.054025173187256,
      "learning_rate": 1.6294117647058823e-05,
      "loss": 1.9746,
      "step": 5730
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.746273994445801,
      "learning_rate": 1.623529411764706e-05,
      "loss": 1.8368,
      "step": 5740
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9433891773223877,
      "learning_rate": 1.6176470588235296e-05,
      "loss": 1.6425,
      "step": 5750
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.039980173110962,
      "learning_rate": 1.611764705882353e-05,
      "loss": 1.3105,
      "step": 5760
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.1753711700439453,
      "learning_rate": 1.6058823529411766e-05,
      "loss": 1.5399,
      "step": 5770
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4730148315429688,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.6909,
      "step": 5780
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.195091485977173,
      "learning_rate": 1.5941176470588236e-05,
      "loss": 1.5532,
      "step": 5790
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.242722749710083,
      "learning_rate": 1.588235294117647e-05,
      "loss": 1.3443,
      "step": 5800
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.663187265396118,
      "learning_rate": 1.5823529411764706e-05,
      "loss": 1.7716,
      "step": 5810
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.984532117843628,
      "learning_rate": 1.5764705882352943e-05,
      "loss": 1.9118,
      "step": 5820
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.8582067489624023,
      "learning_rate": 1.570588235294118e-05,
      "loss": 1.8337,
      "step": 5830
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.4174323081970215,
      "learning_rate": 1.5647058823529412e-05,
      "loss": 1.3556,
      "step": 5840
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.855175018310547,
      "learning_rate": 1.558823529411765e-05,
      "loss": 1.8038,
      "step": 5850
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.1009440422058105,
      "learning_rate": 1.5529411764705882e-05,
      "loss": 1.6137,
      "step": 5860
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.7440035343170166,
      "learning_rate": 1.5470588235294116e-05,
      "loss": 2.0135,
      "step": 5870
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.050193786621094,
      "learning_rate": 1.5411764705882352e-05,
      "loss": 1.8156,
      "step": 5880
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.3516576290130615,
      "learning_rate": 1.535294117647059e-05,
      "loss": 1.4762,
      "step": 5890
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.2386441230773926,
      "learning_rate": 1.5294117647058826e-05,
      "loss": 1.4955,
      "step": 5900
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.98077917098999,
      "learning_rate": 1.5235294117647059e-05,
      "loss": 1.9772,
      "step": 5910
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.340733289718628,
      "learning_rate": 1.5176470588235295e-05,
      "loss": 1.6249,
      "step": 5920
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.2138595581054688,
      "learning_rate": 1.511764705882353e-05,
      "loss": 2.1267,
      "step": 5930
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.781322479248047,
      "learning_rate": 1.5058823529411764e-05,
      "loss": 1.1273,
      "step": 5940
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3579776287078857,
      "learning_rate": 1.5e-05,
      "loss": 1.1179,
      "step": 5950
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.54550838470459,
      "learning_rate": 1.4941176470588237e-05,
      "loss": 1.725,
      "step": 5960
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.512368679046631,
      "learning_rate": 1.4882352941176472e-05,
      "loss": 1.4196,
      "step": 5970
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.7265970706939697,
      "learning_rate": 1.4823529411764705e-05,
      "loss": 1.5858,
      "step": 5980
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.593707799911499,
      "learning_rate": 1.4764705882352942e-05,
      "loss": 1.6365,
      "step": 5990
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.628344774246216,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 1.4697,
      "step": 6000
    },
    {
      "epoch": 0.77,
      "eval_bleu-4": 0.0075384362377150915,
      "eval_rouge-1": 15.405778,
      "eval_rouge-2": 2.378298,
      "eval_rouge-l": 7.8887540000000005,
      "eval_runtime": 784.1905,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 6000
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.611633777618408,
      "learning_rate": 1.4647058823529414e-05,
      "loss": 1.4664,
      "step": 6010
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.4856114387512207,
      "learning_rate": 1.4588235294117647e-05,
      "loss": 1.3622,
      "step": 6020
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.73203444480896,
      "learning_rate": 1.4529411764705883e-05,
      "loss": 1.7125,
      "step": 6030
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.6489453315734863,
      "learning_rate": 1.4470588235294118e-05,
      "loss": 1.6105,
      "step": 6040
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.801459550857544,
      "learning_rate": 1.4411764705882352e-05,
      "loss": 2.0575,
      "step": 6050
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.6260125637054443,
      "learning_rate": 1.4352941176470588e-05,
      "loss": 1.5411,
      "step": 6060
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.196812629699707,
      "learning_rate": 1.4294117647058825e-05,
      "loss": 1.9786,
      "step": 6070
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.1590399742126465,
      "learning_rate": 1.423529411764706e-05,
      "loss": 1.2844,
      "step": 6080
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3275904655456543,
      "learning_rate": 1.4176470588235293e-05,
      "loss": 1.5169,
      "step": 6090
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.5723135471343994,
      "learning_rate": 1.411764705882353e-05,
      "loss": 1.9806,
      "step": 6100
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.074934244155884,
      "learning_rate": 1.4058823529411767e-05,
      "loss": 1.5288,
      "step": 6110
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.9512646198272705,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.5641,
      "step": 6120
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.973487138748169,
      "learning_rate": 1.3941176470588235e-05,
      "loss": 1.5302,
      "step": 6130
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.005894660949707,
      "learning_rate": 1.3882352941176471e-05,
      "loss": 1.8903,
      "step": 6140
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.417217254638672,
      "learning_rate": 1.3823529411764708e-05,
      "loss": 1.6867,
      "step": 6150
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.023553848266602,
      "learning_rate": 1.3764705882352941e-05,
      "loss": 1.625,
      "step": 6160
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.98600172996521,
      "learning_rate": 1.3705882352941176e-05,
      "loss": 1.661,
      "step": 6170
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.360274076461792,
      "learning_rate": 1.3647058823529413e-05,
      "loss": 1.7607,
      "step": 6180
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.959268569946289,
      "learning_rate": 1.358823529411765e-05,
      "loss": 1.6087,
      "step": 6190
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2757089138031006,
      "learning_rate": 1.3529411764705883e-05,
      "loss": 1.5009,
      "step": 6200
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.5209758281707764,
      "learning_rate": 1.3470588235294118e-05,
      "loss": 1.9712,
      "step": 6210
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.168354034423828,
      "learning_rate": 1.3411764705882354e-05,
      "loss": 1.5755,
      "step": 6220
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.097071170806885,
      "learning_rate": 1.3352941176470588e-05,
      "loss": 1.5987,
      "step": 6230
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.703803300857544,
      "learning_rate": 1.3294117647058824e-05,
      "loss": 1.5206,
      "step": 6240
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8277041912078857,
      "learning_rate": 1.323529411764706e-05,
      "loss": 1.6428,
      "step": 6250
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.362082004547119,
      "learning_rate": 1.3176470588235296e-05,
      "loss": 2.175,
      "step": 6260
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.756423234939575,
      "learning_rate": 1.311764705882353e-05,
      "loss": 1.286,
      "step": 6270
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.6787593364715576,
      "learning_rate": 1.3058823529411764e-05,
      "loss": 1.6963,
      "step": 6280
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.1301724910736084,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.4253,
      "step": 6290
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.9380977153778076,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 1.725,
      "step": 6300
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.4473273754119873,
      "learning_rate": 1.288235294117647e-05,
      "loss": 1.8884,
      "step": 6310
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.362717866897583,
      "learning_rate": 1.2823529411764706e-05,
      "loss": 2.272,
      "step": 6320
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.375959873199463,
      "learning_rate": 1.2764705882352942e-05,
      "loss": 1.297,
      "step": 6330
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.9247682094573975,
      "learning_rate": 1.2705882352941176e-05,
      "loss": 1.8856,
      "step": 6340
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.901674270629883,
      "learning_rate": 1.2647058823529412e-05,
      "loss": 2.1449,
      "step": 6350
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.827876567840576,
      "learning_rate": 1.2588235294117647e-05,
      "loss": 1.5612,
      "step": 6360
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.955299139022827,
      "learning_rate": 1.2529411764705884e-05,
      "loss": 1.6158,
      "step": 6370
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.538914442062378,
      "learning_rate": 1.2470588235294119e-05,
      "loss": 1.3552,
      "step": 6380
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.737494945526123,
      "learning_rate": 1.2411764705882354e-05,
      "loss": 1.8992,
      "step": 6390
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.31912899017334,
      "learning_rate": 1.2352941176470589e-05,
      "loss": 1.8619,
      "step": 6400
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.859616756439209,
      "learning_rate": 1.2294117647058824e-05,
      "loss": 1.4685,
      "step": 6410
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.371131420135498,
      "learning_rate": 1.223529411764706e-05,
      "loss": 1.3767,
      "step": 6420
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.810703992843628,
      "learning_rate": 1.2176470588235295e-05,
      "loss": 1.6222,
      "step": 6430
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.057846784591675,
      "learning_rate": 1.2117647058823529e-05,
      "loss": 1.5846,
      "step": 6440
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.915127277374268,
      "learning_rate": 1.2058823529411765e-05,
      "loss": 1.92,
      "step": 6450
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.082195281982422,
      "learning_rate": 1.2e-05,
      "loss": 1.7999,
      "step": 6460
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.2369797229766846,
      "learning_rate": 1.1941176470588237e-05,
      "loss": 1.8121,
      "step": 6470
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.4902472496032715,
      "learning_rate": 1.188235294117647e-05,
      "loss": 1.7193,
      "step": 6480
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.3169312477111816,
      "learning_rate": 1.1823529411764707e-05,
      "loss": 2.0704,
      "step": 6490
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.5403921604156494,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 1.7147,
      "step": 6500
    },
    {
      "epoch": 0.84,
      "eval_bleu-4": 0.007625273459289038,
      "eval_rouge-1": 15.288832000000003,
      "eval_rouge-2": 2.4890179999999997,
      "eval_rouge-l": 8.676514000000001,
      "eval_runtime": 783.9455,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 6500
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.6864607334136963,
      "learning_rate": 1.1705882352941177e-05,
      "loss": 1.2437,
      "step": 6510
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.091928482055664,
      "learning_rate": 1.1647058823529412e-05,
      "loss": 1.7974,
      "step": 6520
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.4397647380828857,
      "learning_rate": 1.1588235294117647e-05,
      "loss": 1.2681,
      "step": 6530
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.2406861782073975,
      "learning_rate": 1.1529411764705883e-05,
      "loss": 1.4562,
      "step": 6540
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.090031385421753,
      "learning_rate": 1.1470588235294118e-05,
      "loss": 1.337,
      "step": 6550
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.9090335369110107,
      "learning_rate": 1.1411764705882353e-05,
      "loss": 1.7491,
      "step": 6560
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.0065419673919678,
      "learning_rate": 1.1352941176470588e-05,
      "loss": 1.537,
      "step": 6570
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.890044927597046,
      "learning_rate": 1.1294117647058825e-05,
      "loss": 1.2917,
      "step": 6580
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.041441917419434,
      "learning_rate": 1.123529411764706e-05,
      "loss": 1.4691,
      "step": 6590
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.443861246109009,
      "learning_rate": 1.1176470588235295e-05,
      "loss": 1.3127,
      "step": 6600
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.007058143615723,
      "learning_rate": 1.111764705882353e-05,
      "loss": 1.883,
      "step": 6610
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.193353176116943,
      "learning_rate": 1.1058823529411766e-05,
      "loss": 2.0704,
      "step": 6620
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.142164468765259,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.5333,
      "step": 6630
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.1330811977386475,
      "learning_rate": 1.0941176470588235e-05,
      "loss": 1.5225,
      "step": 6640
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.4005885124206543,
      "learning_rate": 1.0882352941176471e-05,
      "loss": 1.4327,
      "step": 6650
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.442115306854248,
      "learning_rate": 1.0823529411764706e-05,
      "loss": 1.2273,
      "step": 6660
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.783170223236084,
      "learning_rate": 1.0764705882352941e-05,
      "loss": 2.3935,
      "step": 6670
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.1871235370635986,
      "learning_rate": 1.0705882352941176e-05,
      "loss": 1.8904,
      "step": 6680
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.7777838706970215,
      "learning_rate": 1.0647058823529413e-05,
      "loss": 1.6128,
      "step": 6690
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.1412761211395264,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 1.4748,
      "step": 6700
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.6043524742126465,
      "learning_rate": 1.0529411764705883e-05,
      "loss": 1.0819,
      "step": 6710
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.713494777679443,
      "learning_rate": 1.0470588235294118e-05,
      "loss": 1.4007,
      "step": 6720
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.857499122619629,
      "learning_rate": 1.0411764705882353e-05,
      "loss": 1.5991,
      "step": 6730
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.3961641788482666,
      "learning_rate": 1.035294117647059e-05,
      "loss": 1.6372,
      "step": 6740
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.751633644104004,
      "learning_rate": 1.0294117647058824e-05,
      "loss": 2.0234,
      "step": 6750
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.1451640129089355,
      "learning_rate": 1.023529411764706e-05,
      "loss": 1.6439,
      "step": 6760
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.402294158935547,
      "learning_rate": 1.0176470588235294e-05,
      "loss": 1.6885,
      "step": 6770
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.953836679458618,
      "learning_rate": 1.0117647058823531e-05,
      "loss": 1.7441,
      "step": 6780
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.266084909439087,
      "learning_rate": 1.0058823529411764e-05,
      "loss": 1.851,
      "step": 6790
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.048292875289917,
      "learning_rate": 1e-05,
      "loss": 1.6931,
      "step": 6800
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.7029569149017334,
      "learning_rate": 9.941176470588236e-06,
      "loss": 1.5843,
      "step": 6810
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.15320086479187,
      "learning_rate": 9.88235294117647e-06,
      "loss": 1.1522,
      "step": 6820
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.0967206954956055,
      "learning_rate": 9.823529411764706e-06,
      "loss": 2.2588,
      "step": 6830
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.9622514247894287,
      "learning_rate": 9.76470588235294e-06,
      "loss": 1.9726,
      "step": 6840
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.808326721191406,
      "learning_rate": 9.705882352941177e-06,
      "loss": 1.7504,
      "step": 6850
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.1177122592926025,
      "learning_rate": 9.647058823529412e-06,
      "loss": 1.611,
      "step": 6860
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.364825963973999,
      "learning_rate": 9.588235294117647e-06,
      "loss": 1.6475,
      "step": 6870
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.1294405460357666,
      "learning_rate": 9.529411764705882e-06,
      "loss": 1.3075,
      "step": 6880
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.5841476917266846,
      "learning_rate": 9.470588235294119e-06,
      "loss": 1.5414,
      "step": 6890
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.0442464351654053,
      "learning_rate": 9.411764705882354e-06,
      "loss": 1.1327,
      "step": 6900
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.5889124870300293,
      "learning_rate": 9.352941176470589e-06,
      "loss": 1.6972,
      "step": 6910
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.437767028808594,
      "learning_rate": 9.294117647058824e-06,
      "loss": 1.9061,
      "step": 6920
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.2194488048553467,
      "learning_rate": 9.235294117647059e-06,
      "loss": 1.3802,
      "step": 6930
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.267409086227417,
      "learning_rate": 9.176470588235295e-06,
      "loss": 1.3407,
      "step": 6940
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.153212547302246,
      "learning_rate": 9.117647058823529e-06,
      "loss": 1.6871,
      "step": 6950
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.300630569458008,
      "learning_rate": 9.058823529411765e-06,
      "loss": 1.8227,
      "step": 6960
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.370073080062866,
      "learning_rate": 9e-06,
      "loss": 1.3903,
      "step": 6970
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.8061845302581787,
      "learning_rate": 8.941176470588237e-06,
      "loss": 1.3135,
      "step": 6980
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.856809616088867,
      "learning_rate": 8.88235294117647e-06,
      "loss": 1.8103,
      "step": 6990
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.862606048583984,
      "learning_rate": 8.823529411764707e-06,
      "loss": 1.94,
      "step": 7000
    },
    {
      "epoch": 0.9,
      "eval_bleu-4": 0.006731918927682514,
      "eval_rouge-1": 15.570216,
      "eval_rouge-2": 2.541124,
      "eval_rouge-l": 7.560594000000001,
      "eval_runtime": 782.1885,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 7000
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.646446704864502,
      "learning_rate": 8.764705882352942e-06,
      "loss": 2.1297,
      "step": 7010
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.004472017288208,
      "learning_rate": 8.705882352941177e-06,
      "loss": 1.075,
      "step": 7020
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.5107009410858154,
      "learning_rate": 8.647058823529412e-06,
      "loss": 1.5851,
      "step": 7030
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.175884485244751,
      "learning_rate": 8.588235294117647e-06,
      "loss": 1.5211,
      "step": 7040
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.133918762207031,
      "learning_rate": 8.529411764705883e-06,
      "loss": 1.7668,
      "step": 7050
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.8129072189331055,
      "learning_rate": 8.470588235294118e-06,
      "loss": 1.6757,
      "step": 7060
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.9374301433563232,
      "learning_rate": 8.411764705882353e-06,
      "loss": 1.7258,
      "step": 7070
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.263219356536865,
      "learning_rate": 8.352941176470588e-06,
      "loss": 2.1927,
      "step": 7080
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.436595439910889,
      "learning_rate": 8.294117647058825e-06,
      "loss": 2.1556,
      "step": 7090
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2949750423431396,
      "learning_rate": 8.23529411764706e-06,
      "loss": 2.0377,
      "step": 7100
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.32637095451355,
      "learning_rate": 8.176470588235295e-06,
      "loss": 1.5216,
      "step": 7110
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.25081467628479,
      "learning_rate": 8.11764705882353e-06,
      "loss": 1.3578,
      "step": 7120
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.209657669067383,
      "learning_rate": 8.058823529411765e-06,
      "loss": 1.3765,
      "step": 7130
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.859359264373779,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.9272,
      "step": 7140
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.0230777263641357,
      "learning_rate": 7.941176470588235e-06,
      "loss": 1.4402,
      "step": 7150
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.4155189990997314,
      "learning_rate": 7.882352941176471e-06,
      "loss": 1.6003,
      "step": 7160
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.3203394412994385,
      "learning_rate": 7.823529411764706e-06,
      "loss": 1.7955,
      "step": 7170
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.321260452270508,
      "learning_rate": 7.764705882352941e-06,
      "loss": 1.8577,
      "step": 7180
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.7816524505615234,
      "learning_rate": 7.705882352941176e-06,
      "loss": 1.4791,
      "step": 7190
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.059154987335205,
      "learning_rate": 7.647058823529413e-06,
      "loss": 2.1156,
      "step": 7200
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4110074043273926,
      "learning_rate": 7.588235294117648e-06,
      "loss": 1.6104,
      "step": 7210
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.780951738357544,
      "learning_rate": 7.529411764705882e-06,
      "loss": 1.5976,
      "step": 7220
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3385560512542725,
      "learning_rate": 7.4705882352941185e-06,
      "loss": 1.4357,
      "step": 7230
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.7388505935668945,
      "learning_rate": 7.411764705882353e-06,
      "loss": 1.1379,
      "step": 7240
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3366196155548096,
      "learning_rate": 7.3529411764705884e-06,
      "loss": 1.8873,
      "step": 7250
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.7234346866607666,
      "learning_rate": 7.294117647058823e-06,
      "loss": 1.6727,
      "step": 7260
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.513481855392456,
      "learning_rate": 7.235294117647059e-06,
      "loss": 1.2877,
      "step": 7270
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.8105504512786865,
      "learning_rate": 7.176470588235294e-06,
      "loss": 1.0899,
      "step": 7280
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.7343649864196777,
      "learning_rate": 7.11764705882353e-06,
      "loss": 1.3093,
      "step": 7290
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.180882453918457,
      "learning_rate": 7.058823529411765e-06,
      "loss": 1.5124,
      "step": 7300
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5130836963653564,
      "learning_rate": 7.000000000000001e-06,
      "loss": 1.2381,
      "step": 7310
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.685592174530029,
      "learning_rate": 6.941176470588236e-06,
      "loss": 1.8148,
      "step": 7320
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.304349422454834,
      "learning_rate": 6.882352941176471e-06,
      "loss": 1.7098,
      "step": 7330
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.3865039348602295,
      "learning_rate": 6.8235294117647065e-06,
      "loss": 1.8773,
      "step": 7340
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3810949325561523,
      "learning_rate": 6.7647058823529414e-06,
      "loss": 1.5051,
      "step": 7350
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8096609115600586,
      "learning_rate": 6.705882352941177e-06,
      "loss": 1.4109,
      "step": 7360
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.727371096611023,
      "learning_rate": 6.647058823529412e-06,
      "loss": 1.3694,
      "step": 7370
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.4365603923797607,
      "learning_rate": 6.588235294117648e-06,
      "loss": 1.9225,
      "step": 7380
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.806993246078491,
      "learning_rate": 6.529411764705882e-06,
      "loss": 0.9884,
      "step": 7390
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.813124179840088,
      "learning_rate": 6.470588235294119e-06,
      "loss": 1.83,
      "step": 7400
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.611473560333252,
      "learning_rate": 6.411764705882353e-06,
      "loss": 1.8114,
      "step": 7410
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.298222780227661,
      "learning_rate": 6.352941176470588e-06,
      "loss": 1.8119,
      "step": 7420
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.113568067550659,
      "learning_rate": 6.294117647058824e-06,
      "loss": 1.4768,
      "step": 7430
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.514218807220459,
      "learning_rate": 6.2352941176470595e-06,
      "loss": 1.3601,
      "step": 7440
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.6552891731262207,
      "learning_rate": 6.1764705882352944e-06,
      "loss": 0.9092,
      "step": 7450
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.437473773956299,
      "learning_rate": 6.11764705882353e-06,
      "loss": 1.3991,
      "step": 7460
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.4134714603424072,
      "learning_rate": 6.058823529411764e-06,
      "loss": 1.3786,
      "step": 7470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.736924886703491,
      "learning_rate": 6e-06,
      "loss": 1.9205,
      "step": 7480
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.360660552978516,
      "learning_rate": 5.941176470588235e-06,
      "loss": 1.3767,
      "step": 7490
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.680051565170288,
      "learning_rate": 5.882352941176471e-06,
      "loss": 1.5532,
      "step": 7500
    },
    {
      "epoch": 0.97,
      "eval_bleu-4": 0.009593433836479506,
      "eval_rouge-1": 15.89938,
      "eval_rouge-2": 2.5213780000000003,
      "eval_rouge-l": 8.984474,
      "eval_runtime": 782.0318,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 7500
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.71847677230835,
      "learning_rate": 5.823529411764706e-06,
      "loss": 1.6,
      "step": 7510
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.1534159183502197,
      "learning_rate": 5.764705882352942e-06,
      "loss": 1.633,
      "step": 7520
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.8363564014434814,
      "learning_rate": 5.705882352941177e-06,
      "loss": 1.6314,
      "step": 7530
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.2308220863342285,
      "learning_rate": 5.6470588235294125e-06,
      "loss": 1.2594,
      "step": 7540
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.161641597747803,
      "learning_rate": 5.588235294117647e-06,
      "loss": 1.5532,
      "step": 7550
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.4005630016326904,
      "learning_rate": 5.529411764705883e-06,
      "loss": 1.5216,
      "step": 7560
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.822962522506714,
      "learning_rate": 5.470588235294117e-06,
      "loss": 1.5994,
      "step": 7570
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.973808765411377,
      "learning_rate": 5.411764705882353e-06,
      "loss": 2.1962,
      "step": 7580
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.726978063583374,
      "learning_rate": 5.352941176470588e-06,
      "loss": 1.3463,
      "step": 7590
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.4607038497924805,
      "learning_rate": 5.294117647058824e-06,
      "loss": 1.925,
      "step": 7600
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.13101863861084,
      "learning_rate": 5.235294117647059e-06,
      "loss": 1.5955,
      "step": 7610
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.256072759628296,
      "learning_rate": 5.176470588235295e-06,
      "loss": 1.3956,
      "step": 7620
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.03927755355835,
      "learning_rate": 5.11764705882353e-06,
      "loss": 1.5978,
      "step": 7630
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.676259994506836,
      "learning_rate": 5.0588235294117654e-06,
      "loss": 1.7446,
      "step": 7640
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.771000385284424,
      "learning_rate": 5e-06,
      "loss": 1.357,
      "step": 7650
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.014634609222412,
      "learning_rate": 4.941176470588235e-06,
      "loss": 2.0084,
      "step": 7660
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5348377227783203,
      "learning_rate": 4.88235294117647e-06,
      "loss": 1.1987,
      "step": 7670
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.960973024368286,
      "learning_rate": 4.823529411764706e-06,
      "loss": 1.2866,
      "step": 7680
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.6085784435272217,
      "learning_rate": 4.764705882352941e-06,
      "loss": 1.9874,
      "step": 7690
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.288393020629883,
      "learning_rate": 4.705882352941177e-06,
      "loss": 1.794,
      "step": 7700
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.6128602027893066,
      "learning_rate": 4.647058823529412e-06,
      "loss": 1.2694,
      "step": 7710
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.779502868652344,
      "learning_rate": 4.588235294117648e-06,
      "loss": 1.475,
      "step": 7720
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.542275905609131,
      "learning_rate": 4.529411764705883e-06,
      "loss": 1.9129,
      "step": 7730
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.1788370609283447,
      "learning_rate": 4.4705882352941184e-06,
      "loss": 1.8314,
      "step": 7740
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.340839385986328,
      "learning_rate": 4.411764705882353e-06,
      "loss": 1.2634,
      "step": 7750
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.112680435180664,
      "learning_rate": 4.352941176470588e-06,
      "loss": 1.8146,
      "step": 7760
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.8922107219696045,
      "learning_rate": 4.294117647058823e-06,
      "loss": 1.489,
      "step": 7770
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.041977882385254,
      "learning_rate": 4.235294117647059e-06,
      "loss": 1.7222,
      "step": 7780
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.403867721557617,
      "learning_rate": 4.176470588235294e-06,
      "loss": 1.2809,
      "step": 7790
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.896369218826294,
      "learning_rate": 4.11764705882353e-06,
      "loss": 1.5618,
      "step": 7800
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.1166980266571045,
      "learning_rate": 4.058823529411765e-06,
      "loss": 1.2265,
      "step": 7810
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.6795051097869873,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.6494,
      "step": 7820
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.591197967529297,
      "learning_rate": 3.941176470588236e-06,
      "loss": 1.4307,
      "step": 7830
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.518972158432007,
      "learning_rate": 3.882352941176471e-06,
      "loss": 1.8765,
      "step": 7840
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.779620409011841,
      "learning_rate": 3.823529411764706e-06,
      "loss": 1.5479,
      "step": 7850
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.2185020446777344,
      "learning_rate": 3.764705882352941e-06,
      "loss": 1.6617,
      "step": 7860
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.2548749446868896,
      "learning_rate": 3.7058823529411763e-06,
      "loss": 1.6723,
      "step": 7870
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.7990880012512207,
      "learning_rate": 3.6470588235294117e-06,
      "loss": 1.7405,
      "step": 7880
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.910766124725342,
      "learning_rate": 3.588235294117647e-06,
      "loss": 2.0006,
      "step": 7890
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.5747230052948,
      "learning_rate": 3.5294117647058825e-06,
      "loss": 1.645,
      "step": 7900
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.0969908237457275,
      "learning_rate": 3.470588235294118e-06,
      "loss": 1.6721,
      "step": 7910
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.574718952178955,
      "learning_rate": 3.4117647058823532e-06,
      "loss": 1.7017,
      "step": 7920
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.377849817276001,
      "learning_rate": 3.3529411764705886e-06,
      "loss": 1.7278,
      "step": 7930
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.87729549407959,
      "learning_rate": 3.294117647058824e-06,
      "loss": 1.909,
      "step": 7940
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.908487796783447,
      "learning_rate": 3.2352941176470594e-06,
      "loss": 1.9349,
      "step": 7950
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.2365643978118896,
      "learning_rate": 3.176470588235294e-06,
      "loss": 1.1952,
      "step": 7960
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.8705697059631348,
      "learning_rate": 3.1176470588235297e-06,
      "loss": 1.6841,
      "step": 7970
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.276884078979492,
      "learning_rate": 3.058823529411765e-06,
      "loss": 2.0685,
      "step": 7980
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.948915719985962,
      "learning_rate": 3e-06,
      "loss": 1.6244,
      "step": 7990
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.669185161590576,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 1.6964,
      "step": 8000
    },
    {
      "epoch": 1.03,
      "eval_bleu-4": 0.007992538728719975,
      "eval_rouge-1": 15.592868000000003,
      "eval_rouge-2": 2.4233960000000003,
      "eval_rouge-l": 8.554862,
      "eval_runtime": 783.0592,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 8000
    }
  ],
  "logging_steps": 10,
  "max_steps": 8500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 2.11151685792854e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
