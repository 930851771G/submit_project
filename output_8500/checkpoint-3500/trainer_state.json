{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.45079855744461617,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.7396549582481384,
      "learning_rate": 4.994117647058824e-05,
      "loss": 2.0843,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7169257998466492,
      "learning_rate": 4.9882352941176476e-05,
      "loss": 2.0063,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.5498374700546265,
      "learning_rate": 4.9823529411764706e-05,
      "loss": 1.4857,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9123143553733826,
      "learning_rate": 4.976470588235294e-05,
      "loss": 1.9479,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6916724443435669,
      "learning_rate": 4.970588235294118e-05,
      "loss": 2.0631,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.715797483921051,
      "learning_rate": 4.9647058823529416e-05,
      "loss": 2.3826,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5133962631225586,
      "learning_rate": 4.958823529411765e-05,
      "loss": 1.6836,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7555455565452576,
      "learning_rate": 4.952941176470588e-05,
      "loss": 1.8862,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7520318031311035,
      "learning_rate": 4.947058823529412e-05,
      "loss": 2.5824,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6737620234489441,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 2.1768,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6378394961357117,
      "learning_rate": 4.935294117647059e-05,
      "loss": 1.4663,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6694679260253906,
      "learning_rate": 4.929411764705882e-05,
      "loss": 1.9835,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8011227250099182,
      "learning_rate": 4.9235294117647065e-05,
      "loss": 2.1732,
      "step": 130
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5817644596099854,
      "learning_rate": 4.9176470588235295e-05,
      "loss": 1.4515,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.65079265832901,
      "learning_rate": 4.911764705882353e-05,
      "loss": 2.0902,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.681136429309845,
      "learning_rate": 4.905882352941177e-05,
      "loss": 1.7423,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.865554928779602,
      "learning_rate": 4.9e-05,
      "loss": 1.747,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6741632223129272,
      "learning_rate": 4.894117647058824e-05,
      "loss": 2.4369,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8510251045227051,
      "learning_rate": 4.888235294117647e-05,
      "loss": 2.0585,
      "step": 190
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9345579147338867,
      "learning_rate": 4.882352941176471e-05,
      "loss": 1.7128,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6858922243118286,
      "learning_rate": 4.8764705882352945e-05,
      "loss": 2.356,
      "step": 210
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1562786102294922,
      "learning_rate": 4.870588235294118e-05,
      "loss": 1.8626,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8216276168823242,
      "learning_rate": 4.864705882352941e-05,
      "loss": 1.6861,
      "step": 230
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6591823101043701,
      "learning_rate": 4.858823529411765e-05,
      "loss": 1.8522,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8712974190711975,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 2.4756,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.945023238658905,
      "learning_rate": 4.8470588235294115e-05,
      "loss": 1.8086,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8521285057067871,
      "learning_rate": 4.841176470588236e-05,
      "loss": 2.0532,
      "step": 270
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8471000790596008,
      "learning_rate": 4.835294117647059e-05,
      "loss": 1.8673,
      "step": 280
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7142120003700256,
      "learning_rate": 4.829411764705883e-05,
      "loss": 1.6822,
      "step": 290
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2705433368682861,
      "learning_rate": 4.823529411764706e-05,
      "loss": 2.0034,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.242003083229065,
      "learning_rate": 4.81764705882353e-05,
      "loss": 2.0078,
      "step": 310
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7385304570198059,
      "learning_rate": 4.8117647058823535e-05,
      "loss": 1.8828,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9220168590545654,
      "learning_rate": 4.8058823529411765e-05,
      "loss": 2.1458,
      "step": 330
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6831074953079224,
      "learning_rate": 4.8e-05,
      "loss": 1.9469,
      "step": 340
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7665641903877258,
      "learning_rate": 4.794117647058824e-05,
      "loss": 1.6115,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.009366512298584,
      "learning_rate": 4.7882352941176475e-05,
      "loss": 1.6954,
      "step": 360
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.127745509147644,
      "learning_rate": 4.7823529411764704e-05,
      "loss": 2.0792,
      "step": 370
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.008154034614563,
      "learning_rate": 4.776470588235295e-05,
      "loss": 2.5528,
      "step": 380
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.935829758644104,
      "learning_rate": 4.770588235294118e-05,
      "loss": 2.1982,
      "step": 390
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0530284643173218,
      "learning_rate": 4.7647058823529414e-05,
      "loss": 2.0747,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1127703189849854,
      "learning_rate": 4.758823529411765e-05,
      "loss": 2.0066,
      "step": 410
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.904037594795227,
      "learning_rate": 4.752941176470588e-05,
      "loss": 1.5822,
      "step": 420
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3187386989593506,
      "learning_rate": 4.7470588235294124e-05,
      "loss": 2.0417,
      "step": 430
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8978285193443298,
      "learning_rate": 4.7411764705882354e-05,
      "loss": 2.0516,
      "step": 440
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0291705131530762,
      "learning_rate": 4.735294117647059e-05,
      "loss": 2.0509,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8796937465667725,
      "learning_rate": 4.729411764705883e-05,
      "loss": 1.5584,
      "step": 460
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7101024985313416,
      "learning_rate": 4.7235294117647064e-05,
      "loss": 1.7059,
      "step": 470
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1913437843322754,
      "learning_rate": 4.7176470588235294e-05,
      "loss": 1.6747,
      "step": 480
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2967019081115723,
      "learning_rate": 4.711764705882353e-05,
      "loss": 2.0231,
      "step": 490
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1487231254577637,
      "learning_rate": 4.705882352941177e-05,
      "loss": 2.3678,
      "step": 500
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.007578686752745535,
      "eval_rouge-1": 14.861324,
      "eval_rouge-2": 2.4789380000000003,
      "eval_rouge-l": 8.489636,
      "eval_runtime": 791.0178,
      "eval_samples_per_second": 0.063,
      "eval_steps_per_second": 0.005,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1327245235443115,
      "learning_rate": 4.7e-05,
      "loss": 1.4586,
      "step": 510
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0759632587432861,
      "learning_rate": 4.694117647058824e-05,
      "loss": 1.503,
      "step": 520
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2739144563674927,
      "learning_rate": 4.688235294117647e-05,
      "loss": 1.9756,
      "step": 530
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1042938232421875,
      "learning_rate": 4.682352941176471e-05,
      "loss": 1.6475,
      "step": 540
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0690494775772095,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 1.8079,
      "step": 550
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.188957929611206,
      "learning_rate": 4.6705882352941174e-05,
      "loss": 1.839,
      "step": 560
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3997347354888916,
      "learning_rate": 4.664705882352942e-05,
      "loss": 2.1216,
      "step": 570
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2239084243774414,
      "learning_rate": 4.658823529411765e-05,
      "loss": 2.3236,
      "step": 580
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.452799916267395,
      "learning_rate": 4.6529411764705884e-05,
      "loss": 1.3247,
      "step": 590
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1526904106140137,
      "learning_rate": 4.647058823529412e-05,
      "loss": 2.1531,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1472471952438354,
      "learning_rate": 4.641176470588236e-05,
      "loss": 1.8444,
      "step": 610
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2528969049453735,
      "learning_rate": 4.635294117647059e-05,
      "loss": 1.7568,
      "step": 620
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3372067213058472,
      "learning_rate": 4.6294117647058824e-05,
      "loss": 1.6377,
      "step": 630
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.25386381149292,
      "learning_rate": 4.623529411764706e-05,
      "loss": 2.2869,
      "step": 640
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1897941827774048,
      "learning_rate": 4.61764705882353e-05,
      "loss": 2.1509,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.4586433172225952,
      "learning_rate": 4.6117647058823534e-05,
      "loss": 1.6164,
      "step": 660
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8846438527107239,
      "learning_rate": 4.605882352941176e-05,
      "loss": 1.9242,
      "step": 670
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2287791967391968,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.3812,
      "step": 680
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3532061576843262,
      "learning_rate": 4.594117647058824e-05,
      "loss": 1.3757,
      "step": 690
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5462522506713867,
      "learning_rate": 4.588235294117647e-05,
      "loss": 1.9536,
      "step": 700
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5861589908599854,
      "learning_rate": 4.582352941176471e-05,
      "loss": 1.9828,
      "step": 710
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9763641357421875,
      "learning_rate": 4.576470588235294e-05,
      "loss": 1.6749,
      "step": 720
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.961509644985199,
      "learning_rate": 4.5705882352941177e-05,
      "loss": 2.0053,
      "step": 730
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.174042820930481,
      "learning_rate": 4.564705882352941e-05,
      "loss": 2.2366,
      "step": 740
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6947141885757446,
      "learning_rate": 4.558823529411765e-05,
      "loss": 1.5909,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6772977113723755,
      "learning_rate": 4.5529411764705886e-05,
      "loss": 2.1871,
      "step": 760
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5023149251937866,
      "learning_rate": 4.547058823529412e-05,
      "loss": 1.8749,
      "step": 770
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.860402226448059,
      "learning_rate": 4.541176470588235e-05,
      "loss": 1.5551,
      "step": 780
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5062893629074097,
      "learning_rate": 4.535294117647059e-05,
      "loss": 1.7247,
      "step": 790
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.553699254989624,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 2.1275,
      "step": 800
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2932320833206177,
      "learning_rate": 4.5235294117647056e-05,
      "loss": 1.9158,
      "step": 810
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3733667135238647,
      "learning_rate": 4.51764705882353e-05,
      "loss": 1.8575,
      "step": 820
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.5138239860534668,
      "learning_rate": 4.511764705882353e-05,
      "loss": 1.6347,
      "step": 830
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.796334147453308,
      "learning_rate": 4.5058823529411766e-05,
      "loss": 1.8974,
      "step": 840
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7259682416915894,
      "learning_rate": 4.5e-05,
      "loss": 1.9797,
      "step": 850
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2472668886184692,
      "learning_rate": 4.494117647058824e-05,
      "loss": 1.7184,
      "step": 860
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3183062076568604,
      "learning_rate": 4.4882352941176476e-05,
      "loss": 1.2646,
      "step": 870
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7057313919067383,
      "learning_rate": 4.4823529411764706e-05,
      "loss": 1.3718,
      "step": 880
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6512082815170288,
      "learning_rate": 4.476470588235294e-05,
      "loss": 2.0283,
      "step": 890
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8229845762252808,
      "learning_rate": 4.470588235294118e-05,
      "loss": 1.8168,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5238608121871948,
      "learning_rate": 4.4647058823529416e-05,
      "loss": 2.6278,
      "step": 910
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6909865140914917,
      "learning_rate": 4.4588235294117646e-05,
      "loss": 1.8347,
      "step": 920
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7688746452331543,
      "learning_rate": 4.452941176470589e-05,
      "loss": 1.669,
      "step": 930
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.340709924697876,
      "learning_rate": 4.447058823529412e-05,
      "loss": 1.86,
      "step": 940
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4118435382843018,
      "learning_rate": 4.4411764705882356e-05,
      "loss": 1.2219,
      "step": 950
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8621255159378052,
      "learning_rate": 4.435294117647059e-05,
      "loss": 2.0358,
      "step": 960
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.691055178642273,
      "learning_rate": 4.429411764705882e-05,
      "loss": 1.4031,
      "step": 970
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7289830446243286,
      "learning_rate": 4.4235294117647066e-05,
      "loss": 1.4543,
      "step": 980
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.684492588043213,
      "learning_rate": 4.4176470588235296e-05,
      "loss": 1.7481,
      "step": 990
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3468832969665527,
      "learning_rate": 4.411764705882353e-05,
      "loss": 2.1087,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "eval_bleu-4": 0.009577832318973968,
      "eval_rouge-1": 15.305781999999999,
      "eval_rouge-2": 2.5396780000000003,
      "eval_rouge-l": 10.07657,
      "eval_runtime": 767.3855,
      "eval_samples_per_second": 0.065,
      "eval_steps_per_second": 0.005,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.4899284839630127,
      "learning_rate": 4.405882352941177e-05,
      "loss": 1.665,
      "step": 1010
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5730372667312622,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.074,
      "step": 1020
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3447985649108887,
      "learning_rate": 4.3941176470588236e-05,
      "loss": 1.9928,
      "step": 1030
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0680789947509766,
      "learning_rate": 4.388235294117647e-05,
      "loss": 1.8004,
      "step": 1040
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.854514241218567,
      "learning_rate": 4.382352941176471e-05,
      "loss": 1.2935,
      "step": 1050
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.194340705871582,
      "learning_rate": 4.376470588235294e-05,
      "loss": 1.3931,
      "step": 1060
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.5379902124404907,
      "learning_rate": 4.370588235294118e-05,
      "loss": 1.6494,
      "step": 1070
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.519855260848999,
      "learning_rate": 4.364705882352941e-05,
      "loss": 2.1072,
      "step": 1080
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2680854797363281,
      "learning_rate": 4.358823529411765e-05,
      "loss": 1.7901,
      "step": 1090
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3285330533981323,
      "learning_rate": 4.3529411764705885e-05,
      "loss": 1.918,
      "step": 1100
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0877158641815186,
      "learning_rate": 4.3470588235294115e-05,
      "loss": 2.2697,
      "step": 1110
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4456621408462524,
      "learning_rate": 4.341176470588236e-05,
      "loss": 1.7907,
      "step": 1120
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.037639617919922,
      "learning_rate": 4.335294117647059e-05,
      "loss": 1.7176,
      "step": 1130
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8759605884552002,
      "learning_rate": 4.3294117647058825e-05,
      "loss": 2.215,
      "step": 1140
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1268205642700195,
      "learning_rate": 4.323529411764706e-05,
      "loss": 1.5476,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7071746587753296,
      "learning_rate": 4.31764705882353e-05,
      "loss": 1.5471,
      "step": 1160
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.3370885848999023,
      "learning_rate": 4.311764705882353e-05,
      "loss": 1.5448,
      "step": 1170
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2933474779129028,
      "learning_rate": 4.3058823529411765e-05,
      "loss": 1.7699,
      "step": 1180
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9315828084945679,
      "learning_rate": 4.3e-05,
      "loss": 1.9255,
      "step": 1190
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8792698383331299,
      "learning_rate": 4.294117647058823e-05,
      "loss": 1.7756,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7812600135803223,
      "learning_rate": 4.2882352941176475e-05,
      "loss": 1.9272,
      "step": 1210
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5101515054702759,
      "learning_rate": 4.2823529411764705e-05,
      "loss": 1.792,
      "step": 1220
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5062429904937744,
      "learning_rate": 4.276470588235295e-05,
      "loss": 1.962,
      "step": 1230
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.002393960952759,
      "learning_rate": 4.270588235294118e-05,
      "loss": 1.7518,
      "step": 1240
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4836792945861816,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 1.752,
      "step": 1250
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2557687759399414,
      "learning_rate": 4.258823529411765e-05,
      "loss": 1.6095,
      "step": 1260
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9959425926208496,
      "learning_rate": 4.252941176470588e-05,
      "loss": 1.9296,
      "step": 1270
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9475791454315186,
      "learning_rate": 4.247058823529412e-05,
      "loss": 2.0554,
      "step": 1280
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0245769023895264,
      "learning_rate": 4.2411764705882355e-05,
      "loss": 2.3018,
      "step": 1290
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6179943084716797,
      "learning_rate": 4.235294117647059e-05,
      "loss": 1.3739,
      "step": 1300
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7077521085739136,
      "learning_rate": 4.229411764705882e-05,
      "loss": 1.4225,
      "step": 1310
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9001059532165527,
      "learning_rate": 4.2235294117647065e-05,
      "loss": 1.7756,
      "step": 1320
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.234105348587036,
      "learning_rate": 4.2176470588235294e-05,
      "loss": 2.0502,
      "step": 1330
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.6927742958068848,
      "learning_rate": 4.211764705882353e-05,
      "loss": 2.1774,
      "step": 1340
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7491880655288696,
      "learning_rate": 4.205882352941177e-05,
      "loss": 1.9381,
      "step": 1350
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.949735403060913,
      "learning_rate": 4.2e-05,
      "loss": 2.0165,
      "step": 1360
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9890642166137695,
      "learning_rate": 4.194117647058824e-05,
      "loss": 1.607,
      "step": 1370
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5039284229278564,
      "learning_rate": 4.188235294117647e-05,
      "loss": 2.0575,
      "step": 1380
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7638623714447021,
      "learning_rate": 4.182352941176471e-05,
      "loss": 1.6077,
      "step": 1390
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7925562858581543,
      "learning_rate": 4.1764705882352944e-05,
      "loss": 2.2187,
      "step": 1400
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.825470209121704,
      "learning_rate": 4.170588235294118e-05,
      "loss": 2.0608,
      "step": 1410
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.746583342552185,
      "learning_rate": 4.164705882352941e-05,
      "loss": 1.668,
      "step": 1420
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.063490629196167,
      "learning_rate": 4.158823529411765e-05,
      "loss": 1.9237,
      "step": 1430
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.013375997543335,
      "learning_rate": 4.1529411764705884e-05,
      "loss": 2.0703,
      "step": 1440
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0612082481384277,
      "learning_rate": 4.147058823529412e-05,
      "loss": 1.7305,
      "step": 1450
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9417744874954224,
      "learning_rate": 4.141176470588236e-05,
      "loss": 1.3927,
      "step": 1460
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0757973194122314,
      "learning_rate": 4.135294117647059e-05,
      "loss": 2.2106,
      "step": 1470
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8396998643875122,
      "learning_rate": 4.129411764705883e-05,
      "loss": 1.5323,
      "step": 1480
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0148532390594482,
      "learning_rate": 4.123529411764706e-05,
      "loss": 2.2317,
      "step": 1490
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7623422145843506,
      "learning_rate": 4.11764705882353e-05,
      "loss": 1.7156,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "eval_bleu-4": 0.008565046644483211,
      "eval_rouge-1": 15.911608,
      "eval_rouge-2": 2.16901,
      "eval_rouge-l": 9.547432,
      "eval_runtime": 771.8785,
      "eval_samples_per_second": 0.065,
      "eval_steps_per_second": 0.005,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4623600244522095,
      "learning_rate": 4.1117647058823534e-05,
      "loss": 1.4984,
      "step": 1510
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.6378333568573,
      "learning_rate": 4.1058823529411764e-05,
      "loss": 2.2059,
      "step": 1520
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4674177169799805,
      "learning_rate": 4.1e-05,
      "loss": 2.2057,
      "step": 1530
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.5032272338867188,
      "learning_rate": 4.094117647058824e-05,
      "loss": 1.6221,
      "step": 1540
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6714071035385132,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 1.8375,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4111716747283936,
      "learning_rate": 4.082352941176471e-05,
      "loss": 1.8757,
      "step": 1560
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.114696741104126,
      "learning_rate": 4.076470588235295e-05,
      "loss": 1.6072,
      "step": 1570
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.435027003288269,
      "learning_rate": 4.070588235294118e-05,
      "loss": 1.6893,
      "step": 1580
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1450493335723877,
      "learning_rate": 4.0647058823529414e-05,
      "loss": 2.259,
      "step": 1590
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.252087354660034,
      "learning_rate": 4.058823529411765e-05,
      "loss": 1.3803,
      "step": 1600
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0177221298217773,
      "learning_rate": 4.052941176470588e-05,
      "loss": 1.9951,
      "step": 1610
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0915579795837402,
      "learning_rate": 4.0470588235294124e-05,
      "loss": 1.2339,
      "step": 1620
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0992345809936523,
      "learning_rate": 4.0411764705882353e-05,
      "loss": 2.0861,
      "step": 1630
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6855508089065552,
      "learning_rate": 4.035294117647059e-05,
      "loss": 2.356,
      "step": 1640
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.831886649131775,
      "learning_rate": 4.029411764705883e-05,
      "loss": 1.7846,
      "step": 1650
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.987322211265564,
      "learning_rate": 4.023529411764706e-05,
      "loss": 1.4786,
      "step": 1660
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8036322593688965,
      "learning_rate": 4.01764705882353e-05,
      "loss": 1.9509,
      "step": 1670
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.100874900817871,
      "learning_rate": 4.011764705882353e-05,
      "loss": 1.7814,
      "step": 1680
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.975669503211975,
      "learning_rate": 4.005882352941177e-05,
      "loss": 1.6768,
      "step": 1690
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5067853927612305,
      "learning_rate": 4e-05,
      "loss": 1.4431,
      "step": 1700
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.893838882446289,
      "learning_rate": 3.994117647058824e-05,
      "loss": 1.7137,
      "step": 1710
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8860816955566406,
      "learning_rate": 3.988235294117647e-05,
      "loss": 1.8672,
      "step": 1720
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.496612548828125,
      "learning_rate": 3.9823529411764706e-05,
      "loss": 2.4665,
      "step": 1730
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1365878582000732,
      "learning_rate": 3.976470588235294e-05,
      "loss": 2.0322,
      "step": 1740
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0327188968658447,
      "learning_rate": 3.970588235294117e-05,
      "loss": 1.7082,
      "step": 1750
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.6613212823867798,
      "learning_rate": 3.9647058823529416e-05,
      "loss": 1.4887,
      "step": 1760
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4245240688323975,
      "learning_rate": 3.9588235294117646e-05,
      "loss": 1.634,
      "step": 1770
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9364699125289917,
      "learning_rate": 3.952941176470588e-05,
      "loss": 1.8005,
      "step": 1780
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9637260437011719,
      "learning_rate": 3.947058823529412e-05,
      "loss": 1.4218,
      "step": 1790
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3562440872192383,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 1.8847,
      "step": 1800
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.663616895675659,
      "learning_rate": 3.935294117647059e-05,
      "loss": 2.013,
      "step": 1810
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9651999473571777,
      "learning_rate": 3.929411764705882e-05,
      "loss": 2.0958,
      "step": 1820
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.249924421310425,
      "learning_rate": 3.923529411764706e-05,
      "loss": 1.9987,
      "step": 1830
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5808236598968506,
      "learning_rate": 3.9176470588235296e-05,
      "loss": 1.4401,
      "step": 1840
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9374414682388306,
      "learning_rate": 3.911764705882353e-05,
      "loss": 1.5344,
      "step": 1850
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1319642066955566,
      "learning_rate": 3.905882352941176e-05,
      "loss": 1.3285,
      "step": 1860
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3826074600219727,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.4896,
      "step": 1870
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.489104986190796,
      "learning_rate": 3.8941176470588236e-05,
      "loss": 1.7168,
      "step": 1880
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.311724901199341,
      "learning_rate": 3.888235294117647e-05,
      "loss": 2.1339,
      "step": 1890
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.7383129596710205,
      "learning_rate": 3.882352941176471e-05,
      "loss": 1.7705,
      "step": 1900
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7104880809783936,
      "learning_rate": 3.876470588235294e-05,
      "loss": 1.4347,
      "step": 1910
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0491201877593994,
      "learning_rate": 3.870588235294118e-05,
      "loss": 1.4378,
      "step": 1920
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.099395751953125,
      "learning_rate": 3.864705882352941e-05,
      "loss": 1.8832,
      "step": 1930
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.905476450920105,
      "learning_rate": 3.858823529411765e-05,
      "loss": 1.6141,
      "step": 1940
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7137335538864136,
      "learning_rate": 3.8529411764705886e-05,
      "loss": 1.5344,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8573613166809082,
      "learning_rate": 3.847058823529412e-05,
      "loss": 1.4194,
      "step": 1960
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.713721752166748,
      "learning_rate": 3.841176470588235e-05,
      "loss": 1.7601,
      "step": 1970
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.61387038230896,
      "learning_rate": 3.835294117647059e-05,
      "loss": 2.3021,
      "step": 1980
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.510282039642334,
      "learning_rate": 3.8294117647058826e-05,
      "loss": 1.9956,
      "step": 1990
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.722810745239258,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 1.9148,
      "step": 2000
    },
    {
      "epoch": 0.26,
      "eval_bleu-4": 0.007352092261144994,
      "eval_rouge-1": 15.163063999999999,
      "eval_rouge-2": 2.525064,
      "eval_rouge-l": 8.606603999999999,
      "eval_runtime": 782.1357,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 2000
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.468543767929077,
      "learning_rate": 3.81764705882353e-05,
      "loss": 1.5215,
      "step": 2010
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5896573066711426,
      "learning_rate": 3.811764705882353e-05,
      "loss": 1.9634,
      "step": 2020
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9104920625686646,
      "learning_rate": 3.805882352941177e-05,
      "loss": 1.9394,
      "step": 2030
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.058467149734497,
      "learning_rate": 3.8e-05,
      "loss": 1.9284,
      "step": 2040
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8718152046203613,
      "learning_rate": 3.794117647058824e-05,
      "loss": 2.1773,
      "step": 2050
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.121635913848877,
      "learning_rate": 3.7882352941176475e-05,
      "loss": 1.4497,
      "step": 2060
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9446643590927124,
      "learning_rate": 3.7823529411764705e-05,
      "loss": 1.6185,
      "step": 2070
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5567731857299805,
      "learning_rate": 3.776470588235294e-05,
      "loss": 1.8375,
      "step": 2080
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8681668043136597,
      "learning_rate": 3.770588235294118e-05,
      "loss": 1.6308,
      "step": 2090
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2197656631469727,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 1.943,
      "step": 2100
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.881116271018982,
      "learning_rate": 3.7588235294117645e-05,
      "loss": 1.4159,
      "step": 2110
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2873406410217285,
      "learning_rate": 3.752941176470588e-05,
      "loss": 2.128,
      "step": 2120
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3979103565216064,
      "learning_rate": 3.747058823529412e-05,
      "loss": 1.8648,
      "step": 2130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0728256702423096,
      "learning_rate": 3.7411764705882355e-05,
      "loss": 1.8529,
      "step": 2140
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1754372119903564,
      "learning_rate": 3.735294117647059e-05,
      "loss": 2.1254,
      "step": 2150
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.388080358505249,
      "learning_rate": 3.729411764705882e-05,
      "loss": 2.0856,
      "step": 2160
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.305142879486084,
      "learning_rate": 3.7235294117647065e-05,
      "loss": 1.9888,
      "step": 2170
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.673713445663452,
      "learning_rate": 3.7176470588235295e-05,
      "loss": 1.2274,
      "step": 2180
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1564624309539795,
      "learning_rate": 3.711764705882353e-05,
      "loss": 1.5416,
      "step": 2190
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9353389739990234,
      "learning_rate": 3.705882352941177e-05,
      "loss": 1.9027,
      "step": 2200
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.773437738418579,
      "learning_rate": 3.7e-05,
      "loss": 2.2377,
      "step": 2210
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0789082050323486,
      "learning_rate": 3.6941176470588235e-05,
      "loss": 1.6267,
      "step": 2220
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.8535796403884888,
      "learning_rate": 3.688235294117647e-05,
      "loss": 1.4833,
      "step": 2230
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7043330669403076,
      "learning_rate": 3.682352941176471e-05,
      "loss": 2.071,
      "step": 2240
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.3449292182922363,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.8475,
      "step": 2250
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4246346950531006,
      "learning_rate": 3.670588235294118e-05,
      "loss": 1.8328,
      "step": 2260
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1732139587402344,
      "learning_rate": 3.664705882352941e-05,
      "loss": 1.6236,
      "step": 2270
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7404873371124268,
      "learning_rate": 3.658823529411765e-05,
      "loss": 2.3478,
      "step": 2280
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.9458601474761963,
      "learning_rate": 3.6529411764705885e-05,
      "loss": 2.0789,
      "step": 2290
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7248296737670898,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 1.2653,
      "step": 2300
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.033937454223633,
      "learning_rate": 3.641176470588236e-05,
      "loss": 1.6143,
      "step": 2310
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9992233514785767,
      "learning_rate": 3.635294117647059e-05,
      "loss": 1.6457,
      "step": 2320
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7832584381103516,
      "learning_rate": 3.6294117647058824e-05,
      "loss": 2.324,
      "step": 2330
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.680030107498169,
      "learning_rate": 3.623529411764706e-05,
      "loss": 1.3203,
      "step": 2340
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0794899463653564,
      "learning_rate": 3.61764705882353e-05,
      "loss": 1.6604,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.57136070728302,
      "learning_rate": 3.6117647058823534e-05,
      "loss": 2.1184,
      "step": 2360
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9183681011199951,
      "learning_rate": 3.6058823529411764e-05,
      "loss": 1.2426,
      "step": 2370
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.8155035972595215,
      "learning_rate": 3.6e-05,
      "loss": 2.0003,
      "step": 2380
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.3117778301239014,
      "learning_rate": 3.594117647058824e-05,
      "loss": 2.0313,
      "step": 2390
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7839088439941406,
      "learning_rate": 3.5882352941176474e-05,
      "loss": 1.6962,
      "step": 2400
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.450000762939453,
      "learning_rate": 3.5823529411764704e-05,
      "loss": 1.5125,
      "step": 2410
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.6440720558166504,
      "learning_rate": 3.576470588235295e-05,
      "loss": 1.8233,
      "step": 2420
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.423382520675659,
      "learning_rate": 3.570588235294118e-05,
      "loss": 1.4507,
      "step": 2430
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.368068218231201,
      "learning_rate": 3.5647058823529414e-05,
      "loss": 2.4774,
      "step": 2440
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7364857196807861,
      "learning_rate": 3.558823529411765e-05,
      "loss": 1.9423,
      "step": 2450
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.179574012756348,
      "learning_rate": 3.552941176470588e-05,
      "loss": 1.2866,
      "step": 2460
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6034932136535645,
      "learning_rate": 3.5470588235294124e-05,
      "loss": 1.2228,
      "step": 2470
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5666322708129883,
      "learning_rate": 3.5411764705882354e-05,
      "loss": 1.9043,
      "step": 2480
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.817185878753662,
      "learning_rate": 3.535294117647059e-05,
      "loss": 1.8711,
      "step": 2490
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4493463039398193,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.9721,
      "step": 2500
    },
    {
      "epoch": 0.32,
      "eval_bleu-4": 0.0061998258956323425,
      "eval_rouge-1": 14.965072,
      "eval_rouge-2": 2.4639860000000002,
      "eval_rouge-l": 8.143062,
      "eval_runtime": 758.1176,
      "eval_samples_per_second": 0.066,
      "eval_steps_per_second": 0.005,
      "step": 2500
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2134475708007812,
      "learning_rate": 3.5235294117647064e-05,
      "loss": 1.6099,
      "step": 2510
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2021071910858154,
      "learning_rate": 3.5176470588235294e-05,
      "loss": 1.3881,
      "step": 2520
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1232693195343018,
      "learning_rate": 3.511764705882353e-05,
      "loss": 1.6546,
      "step": 2530
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.108617067337036,
      "learning_rate": 3.505882352941177e-05,
      "loss": 1.8089,
      "step": 2540
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.071486473083496,
      "learning_rate": 3.5e-05,
      "loss": 1.3186,
      "step": 2550
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.836077928543091,
      "learning_rate": 3.494117647058824e-05,
      "loss": 1.3649,
      "step": 2560
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.297325611114502,
      "learning_rate": 3.488235294117647e-05,
      "loss": 2.0222,
      "step": 2570
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.902653932571411,
      "learning_rate": 3.482352941176471e-05,
      "loss": 1.5175,
      "step": 2580
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.01723051071167,
      "learning_rate": 3.4764705882352944e-05,
      "loss": 1.4074,
      "step": 2590
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3298861980438232,
      "learning_rate": 3.470588235294118e-05,
      "loss": 1.8981,
      "step": 2600
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.603602170944214,
      "learning_rate": 3.464705882352942e-05,
      "loss": 1.9181,
      "step": 2610
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.994647741317749,
      "learning_rate": 3.458823529411765e-05,
      "loss": 1.6716,
      "step": 2620
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.539877414703369,
      "learning_rate": 3.4529411764705883e-05,
      "loss": 1.7304,
      "step": 2630
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.6402556896209717,
      "learning_rate": 3.447058823529412e-05,
      "loss": 1.6744,
      "step": 2640
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.082094669342041,
      "learning_rate": 3.441176470588236e-05,
      "loss": 1.4779,
      "step": 2650
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.156879186630249,
      "learning_rate": 3.4352941176470587e-05,
      "loss": 1.8866,
      "step": 2660
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.1617202758789062,
      "learning_rate": 3.429411764705882e-05,
      "loss": 1.8164,
      "step": 2670
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.369626760482788,
      "learning_rate": 3.423529411764706e-05,
      "loss": 1.5799,
      "step": 2680
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.204664945602417,
      "learning_rate": 3.417647058823529e-05,
      "loss": 2.4022,
      "step": 2690
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.1758205890655518,
      "learning_rate": 3.411764705882353e-05,
      "loss": 1.9857,
      "step": 2700
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.2973663806915283,
      "learning_rate": 3.405882352941176e-05,
      "loss": 1.4774,
      "step": 2710
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.787308692932129,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.7955,
      "step": 2720
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.1035563945770264,
      "learning_rate": 3.3941176470588236e-05,
      "loss": 1.4788,
      "step": 2730
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.386037588119507,
      "learning_rate": 3.388235294117647e-05,
      "loss": 1.3433,
      "step": 2740
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.6990861892700195,
      "learning_rate": 3.382352941176471e-05,
      "loss": 1.5525,
      "step": 2750
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3942036628723145,
      "learning_rate": 3.376470588235294e-05,
      "loss": 2.2214,
      "step": 2760
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.328122138977051,
      "learning_rate": 3.3705882352941176e-05,
      "loss": 1.552,
      "step": 2770
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3242127895355225,
      "learning_rate": 3.364705882352941e-05,
      "loss": 1.5241,
      "step": 2780
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.5346767902374268,
      "learning_rate": 3.358823529411765e-05,
      "loss": 1.6094,
      "step": 2790
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.3012516498565674,
      "learning_rate": 3.352941176470588e-05,
      "loss": 1.7354,
      "step": 2800
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.4818127155303955,
      "learning_rate": 3.347058823529412e-05,
      "loss": 2.1555,
      "step": 2810
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.7537732124328613,
      "learning_rate": 3.341176470588235e-05,
      "loss": 2.043,
      "step": 2820
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6539998054504395,
      "learning_rate": 3.335294117647059e-05,
      "loss": 1.7431,
      "step": 2830
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.231738328933716,
      "learning_rate": 3.3294117647058826e-05,
      "loss": 1.5274,
      "step": 2840
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.149749517440796,
      "learning_rate": 3.3235294117647056e-05,
      "loss": 1.5026,
      "step": 2850
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0494296550750732,
      "learning_rate": 3.31764705882353e-05,
      "loss": 2.1838,
      "step": 2860
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9731146097183228,
      "learning_rate": 3.311764705882353e-05,
      "loss": 1.7802,
      "step": 2870
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8408620357513428,
      "learning_rate": 3.3058823529411766e-05,
      "loss": 1.1811,
      "step": 2880
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1161577701568604,
      "learning_rate": 3.3e-05,
      "loss": 1.3205,
      "step": 2890
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.365225315093994,
      "learning_rate": 3.294117647058824e-05,
      "loss": 1.498,
      "step": 2900
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.881964921951294,
      "learning_rate": 3.288235294117647e-05,
      "loss": 2.1128,
      "step": 2910
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.719506025314331,
      "learning_rate": 3.2823529411764706e-05,
      "loss": 1.4171,
      "step": 2920
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.4906790256500244,
      "learning_rate": 3.276470588235294e-05,
      "loss": 1.3601,
      "step": 2930
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7030961513519287,
      "learning_rate": 3.270588235294118e-05,
      "loss": 1.895,
      "step": 2940
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.264988422393799,
      "learning_rate": 3.2647058823529416e-05,
      "loss": 2.0202,
      "step": 2950
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7987418174743652,
      "learning_rate": 3.2588235294117646e-05,
      "loss": 2.1535,
      "step": 2960
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.3476946353912354,
      "learning_rate": 3.252941176470589e-05,
      "loss": 1.4715,
      "step": 2970
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.9451916217803955,
      "learning_rate": 3.247058823529412e-05,
      "loss": 2.4075,
      "step": 2980
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.436126708984375,
      "learning_rate": 3.2411764705882356e-05,
      "loss": 1.7831,
      "step": 2990
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.074416399002075,
      "learning_rate": 3.235294117647059e-05,
      "loss": 1.062,
      "step": 3000
    },
    {
      "epoch": 0.39,
      "eval_bleu-4": 0.005826690054826956,
      "eval_rouge-1": 14.001019999999999,
      "eval_rouge-2": 2.3419879999999997,
      "eval_rouge-l": 7.307937999999999,
      "eval_runtime": 762.1024,
      "eval_samples_per_second": 0.066,
      "eval_steps_per_second": 0.005,
      "step": 3000
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.691042184829712,
      "learning_rate": 3.229411764705882e-05,
      "loss": 2.2719,
      "step": 3010
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7722816467285156,
      "learning_rate": 3.223529411764706e-05,
      "loss": 1.5644,
      "step": 3020
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.632524013519287,
      "learning_rate": 3.2176470588235295e-05,
      "loss": 1.5764,
      "step": 3030
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.673659086227417,
      "learning_rate": 3.211764705882353e-05,
      "loss": 1.6521,
      "step": 3040
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.392922878265381,
      "learning_rate": 3.205882352941177e-05,
      "loss": 2.2139,
      "step": 3050
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2451045513153076,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.7228,
      "step": 3060
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.53084659576416,
      "learning_rate": 3.1941176470588235e-05,
      "loss": 1.7447,
      "step": 3070
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.699586868286133,
      "learning_rate": 3.188235294117647e-05,
      "loss": 1.5692,
      "step": 3080
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.5168657302856445,
      "learning_rate": 3.182352941176471e-05,
      "loss": 1.3039,
      "step": 3090
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.56040620803833,
      "learning_rate": 3.176470588235294e-05,
      "loss": 1.6238,
      "step": 3100
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.944211721420288,
      "learning_rate": 3.170588235294118e-05,
      "loss": 1.696,
      "step": 3110
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.6964914798736572,
      "learning_rate": 3.164705882352941e-05,
      "loss": 2.1916,
      "step": 3120
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5651791095733643,
      "learning_rate": 3.158823529411765e-05,
      "loss": 1.97,
      "step": 3130
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.657733917236328,
      "learning_rate": 3.1529411764705885e-05,
      "loss": 1.6127,
      "step": 3140
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.64947247505188,
      "learning_rate": 3.147058823529412e-05,
      "loss": 1.3326,
      "step": 3150
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.544785499572754,
      "learning_rate": 3.141176470588236e-05,
      "loss": 1.7461,
      "step": 3160
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8508881330490112,
      "learning_rate": 3.135294117647059e-05,
      "loss": 1.8184,
      "step": 3170
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.8224034309387207,
      "learning_rate": 3.1294117647058825e-05,
      "loss": 1.8938,
      "step": 3180
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.906782627105713,
      "learning_rate": 3.123529411764706e-05,
      "loss": 2.0716,
      "step": 3190
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.4483282566070557,
      "learning_rate": 3.11764705882353e-05,
      "loss": 1.9874,
      "step": 3200
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.664111375808716,
      "learning_rate": 3.111764705882353e-05,
      "loss": 1.6729,
      "step": 3210
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.34389591217041,
      "learning_rate": 3.1058823529411765e-05,
      "loss": 2.0371,
      "step": 3220
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.9973154067993164,
      "learning_rate": 3.1e-05,
      "loss": 1.9267,
      "step": 3230
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4099602699279785,
      "learning_rate": 3.094117647058823e-05,
      "loss": 2.372,
      "step": 3240
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.662079095840454,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 1.5403,
      "step": 3250
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.90064537525177,
      "learning_rate": 3.0823529411764705e-05,
      "loss": 1.5634,
      "step": 3260
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.3251538276672363,
      "learning_rate": 3.076470588235294e-05,
      "loss": 2.2486,
      "step": 3270
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.4151840209960938,
      "learning_rate": 3.070588235294118e-05,
      "loss": 1.7059,
      "step": 3280
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.8048341274261475,
      "learning_rate": 3.0647058823529415e-05,
      "loss": 1.7984,
      "step": 3290
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8354573249816895,
      "learning_rate": 3.058823529411765e-05,
      "loss": 1.0555,
      "step": 3300
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.099708318710327,
      "learning_rate": 3.052941176470588e-05,
      "loss": 1.9228,
      "step": 3310
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5065805912017822,
      "learning_rate": 3.0470588235294118e-05,
      "loss": 1.52,
      "step": 3320
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1178712844848633,
      "learning_rate": 3.0411764705882358e-05,
      "loss": 1.2482,
      "step": 3330
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.271554708480835,
      "learning_rate": 3.035294117647059e-05,
      "loss": 1.8305,
      "step": 3340
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8019886016845703,
      "learning_rate": 3.0294117647058824e-05,
      "loss": 1.8549,
      "step": 3350
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.6712963581085205,
      "learning_rate": 3.023529411764706e-05,
      "loss": 1.7245,
      "step": 3360
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5783627033233643,
      "learning_rate": 3.0176470588235294e-05,
      "loss": 1.7918,
      "step": 3370
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.467336893081665,
      "learning_rate": 3.0117647058823527e-05,
      "loss": 1.9169,
      "step": 3380
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9931050539016724,
      "learning_rate": 3.0058823529411767e-05,
      "loss": 1.2207,
      "step": 3390
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.8606836795806885,
      "learning_rate": 3e-05,
      "loss": 1.5132,
      "step": 3400
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3032968044281006,
      "learning_rate": 2.994117647058824e-05,
      "loss": 1.8237,
      "step": 3410
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3405494689941406,
      "learning_rate": 2.9882352941176474e-05,
      "loss": 2.2718,
      "step": 3420
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3432300090789795,
      "learning_rate": 2.9823529411764707e-05,
      "loss": 1.6407,
      "step": 3430
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.420119285583496,
      "learning_rate": 2.9764705882352944e-05,
      "loss": 2.0881,
      "step": 3440
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6728694438934326,
      "learning_rate": 2.9705882352941177e-05,
      "loss": 1.7052,
      "step": 3450
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.0391194820404053,
      "learning_rate": 2.964705882352941e-05,
      "loss": 1.5705,
      "step": 3460
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4242095947265625,
      "learning_rate": 2.958823529411765e-05,
      "loss": 1.853,
      "step": 3470
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.1080548763275146,
      "learning_rate": 2.9529411764705884e-05,
      "loss": 2.1794,
      "step": 3480
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3734452724456787,
      "learning_rate": 2.9470588235294117e-05,
      "loss": 2.0624,
      "step": 3490
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.275162696838379,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 2.2051,
      "step": 3500
    },
    {
      "epoch": 0.45,
      "eval_bleu-4": 0.006183683822211395,
      "eval_rouge-1": 14.37837,
      "eval_rouge-2": 2.007916,
      "eval_rouge-l": 8.076936,
      "eval_runtime": 781.5516,
      "eval_samples_per_second": 0.064,
      "eval_steps_per_second": 0.005,
      "step": 3500
    }
  ],
  "logging_steps": 10,
  "max_steps": 8500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 9.254029408336282e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
